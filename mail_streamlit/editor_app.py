import streamlit as st
import pandas as pd
import gspread
import datetime
import urllib.parse
import re
from google.cloud import storage

# --- 1. å®šæ•°ãƒ»è¨­å®š ---
try:
    SHEET_ID = st.secrets["google_resources"]["spreadsheet_id"]
    ACCOUNT_STATUS_SHEET_ID = "1_GmWjpypap4rrPGNFYWkwcQE1SoK3QOMJlozEhkBwVM"
    
    GCS_BUCKET_NAME = "auto-poster-images"
    ACCOUNT_OPTIONS = ["A", "B", "C", "D"]
    SHEET_MAP = {opt: f"æŠ•ç¨¿{opt}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ" for opt in ACCOUNT_OPTIONS}
    DF_COLS = ["ã‚¨ãƒªã‚¢", "åº—å", "åª’ä½“", "æŠ•ç¨¿æ™‚é–“", "å¥³ã®å­ã®åå‰", "ã‚¿ã‚¤ãƒˆãƒ«", "æœ¬æ–‡"]
except KeyError:
    st.error("ğŸš¨ secrets.tomlã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- 2. è£œåŠ©é–¢æ•° ---
def normalize_text(s):
    if not s: return ""
    return re.sub(r'\s+', '', str(s)).replace('ã€€', '').lower()

def parse_to_datetime(t_str):
    t_clean = re.sub(r'[^0-9]', '', str(t_str))
    if len(t_clean) == 3: t_clean = "0" + t_clean
    if len(t_clean) == 4:
        try: return datetime.datetime.strptime(t_clean, "%H%M")
        except: return None
    return None

def is_time_match(base_time, target_filename, window_min=20):
    if not base_time: return False
    match = re.match(r'^(\d{3,4})', target_filename)
    if not match: return False
    t_target = parse_to_datetime(match.group(1))
    if not t_target: return False
    diff = abs((base_time - t_target).total_seconds()) / 60
    return diff <= window_min or diff >= (1440 - window_min)

def get_cached_url(blob_name):
    return f"https://storage.googleapis.com/{GCS_BUCKET_NAME}/{urllib.parse.quote(blob_name)}"

# --- 3. APIæ¥ç¶š & ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š ---
@st.cache_resource(ttl=3600)
def get_clients():
    gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
    gcs = storage.Client.from_service_account_info(st.secrets["gcp_service_account"])
    return gc, gcs

GC, GCS_CLIENT = get_clients()

# ã€APIåˆ¶é™å¯¾ç­–ã€‘æ‰‹å‹•æ›´æ–°ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã‚‹ã¾ã§1é€±é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä¿æŒ
@st.cache_data(ttl=604800)
def get_full_sheet_data(sheet_key, worksheet_name):
    try:
        sh = GC.open_by_key(sheet_key)
        ws = sh.worksheet(worksheet_name)
        return ws.get_all_values()
    except Exception as e:
        st.error(f"ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# --- 4. UIæ§‹ç¯‰ ---
st.set_page_config(layout="wide", page_title="å†™ãƒ¡æ—¥è¨˜æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†")

st.markdown("""
    <style>
    [data-testid="stHeader"] { display: none; }
    .block-container { padding-top: 1.5rem !important; padding-bottom: 0rem !important; }
    .stApp h1 { padding-top: 0px !important; margin-top: -15px !important; padding-bottom: 10px !important; margin-bottom: 0px !important; font-size: 1.8rem !important; }
    .filter-panel { background-color: #f1f3f6; padding: 12px 20px; border-radius: 10px; margin-top: 5px !important; margin-bottom: 15px; border: 1px solid #d1d5db; }
    .stTextArea textarea { font-size: 15px; line-height: 1.6; }
    .diary-divider { border-bottom: 2px solid #eee; padding-bottom: 30px; margin-bottom: 30px; }
    .stTabs [data-baseweb="tab-list"] { gap: 8px; }
    </style>
""", unsafe_allow_html=True)

def main():
    st.title("ğŸ“¸ å†™ãƒ¡æ—¥è¨˜æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†")

    tab1, tab2 = st.tabs(["ğŸ“ æ—¥è¨˜ç·¨é›†ãƒ»ç”»åƒç®¡ç†", "ğŸ“Š åº—èˆ—ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³"])

    with tab1:
Â  Â  Â  Â  with st.expander("ğŸ“– ä½¿ã„æ–¹ï¼ˆã‚¯ãƒªãƒƒã‚¯ã§é–‹é–‰ï¼‰", expanded=False):
Â  Â  Â  Â  Â  Â  st.markdown("### ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°ã«ã¤ã„ã¦\nã“ã®ã‚¢ãƒ—ãƒªã¯APIåˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚ã€ä¸€åº¦èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¦ã„ã¾ã™ã€‚ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ç›´æ¥ç·¨é›†ã—ãŸå ´åˆã¯ã€å³ä¸Šã® **ã€ŒğŸ”„ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°ã€** ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  # --- ãƒ¡ã‚¤ãƒ³ç”»é¢ä¸Šéƒ¨ã®é¸æŠãƒ‘ãƒãƒ« ---
Â  Â  Â  Â  st.markdown('<div class="filter-panel">', unsafe_allow_html=True)
Â  Â  Â  Â  c1, c2, c3, c4, c5 = st.columns([1, 1, 1, 1.5, 1]) # æ›´æ–°ãƒœã‚¿ãƒ³ç”¨ã«ã‚«ãƒ©ãƒ è¿½åŠ 
Â  Â  Â  Â Â 
Â  Â  Â  Â  with c1:
Â  Â  Â  Â  Â  Â  sel_acc = st.selectbox("ğŸ‘¤ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", ACCOUNT_OPTIONS, index=0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ğŸ”„ æ‰‹å‹•æ›´æ–°ãƒœã‚¿ãƒ³
Â  Â  Â  Â  with c5:
Â  Â  Â  Â  Â  Â  st.write("") # ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
Â  Â  Â  Â  Â  Â  if st.button("ğŸ”„ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã«æ›´æ–°", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  st.cache_data.clear()
Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
Â  Â  Â  Â  data = get_full_sheet_data(SHEET_ID, SHEET_MAP[sel_acc])
Â  Â  Â  Â Â 
Â  Â  Â  Â  if not data or len(data) <= 1:
Â  Â  Â  Â  Â  Â  st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
Â  Â  Â  Â  Â  Â  st.markdown('</div>', unsafe_allow_html=True)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  full_df = pd.DataFrame(data[1:])
Â  Â  Â  Â  Â  Â  full_df = full_df.iloc[:, :7]
Â  Â  Â  Â  Â  Â  while full_df.shape[1] < 7: full_df[full_df.shape[1]] = ""
Â  Â  Â  Â  Â  Â  full_df.columns = DF_COLS
Â  Â  Â  Â  Â  Â  full_df['__row__'] = range(2, len(data) + 1)
Â  Â  Â  Â  Â  Â  full_df = full_df[full_df["åº—å"].str.strip() != ""]
Â  Â  Â  Â  Â  Â  full_df = full_df[full_df["å¥³ã®å­ã®åå‰"].str.strip() != ""]

Â  Â  Â  Â  Â  Â  with c2:
Â  Â  Â  Â  Â  Â  Â  Â  areas = sorted(full_df["ã‚¨ãƒªã‚¢"].unique())
Â  Â  Â  Â  Â  Â  Â  Â  sel_area = st.selectbox("ğŸ“ ã‚¨ãƒªã‚¢", ["æœªé¸æŠ"] + areas)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  sel_store = "æœªé¸æŠ"
Â  Â  Â  Â  Â  Â  with c3:
Â  Â  Â  Â  Â  Â  Â  Â  if sel_area != "æœªé¸æŠ":
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stores = sorted(full_df[full_df["ã‚¨ãƒªã‚¢"] == sel_area]["åº—å"].unique())
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sel_store = st.selectbox("ğŸ¢ åº—èˆ—", ["æœªé¸æŠ"] + stores)
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.selectbox("ğŸ¢ åº—èˆ—", ["ã‚¨ãƒªã‚¢ã‚’é¸æŠ"], disabled=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  with c4:
Â  Â  Â  Â  Â  Â  Â  Â  search_query = st.text_input("ğŸ” æ¤œç´¢", placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›...")

Â  Â  Â  Â  Â  Â  st.markdown('</div>', unsafe_allow_html=True)

Â  Â  Â  Â  Â  Â  if sel_store == "æœªé¸æŠ":
Â  Â  Â  Â  Â  Â  Â  Â  st.info("ğŸ’¡ ãƒ‘ãƒãƒ«ã‹ã‚‰ã‚¨ãƒªã‚¢ã¨åº—èˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  target_df = full_df[(full_df["ã‚¨ãƒªã‚¢"] == sel_area) & (full_df["åº—å"] == sel_store)]
Â  Â  Â  Â  Â  Â  Â  Â  if search_query:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  q = normalize_text(search_query)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_df = target_df[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_df["å¥³ã®å­ã®åå‰"].apply(normalize_text).str.contains(q) |
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_df["ã‚¿ã‚¤ãƒˆãƒ«"].apply(normalize_text).str.contains(q) |
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_df["æœ¬æ–‡"].apply(normalize_text).str.contains(q) |
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  target_df["æŠ•ç¨¿æ™‚é–“"].str.contains(q)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]

Â  Â  Â  Â  Â  Â  Â  Â  st.subheader(f"ğŸ“Š {sel_store} ({len(target_df)} ä»¶)")

Â  Â  Â  Â  Â  Â  Â  Â  bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
Â  Â  Â  Â  Â  Â  Â  Â  blobs = list(bucket.list_blobs(prefix=f"{sel_area}/"))
Â  Â  Â  Â  Â  Â  Â  Â  store_norm = normalize_text(sel_store)
Â  Â  Â  Â  Â  Â  Â  Â  store_images = [b.name for b in blobs if normalize_text(b.name.split('/')[1]) in [store_norm, normalize_text(f"ãƒ‡ãƒªã˜ã‚ƒ{sel_store}")]]

Â  Â  Â  Â  Â  Â  Â  Â  st.write("---")

Â  Â  Â  Â  Â  Â  Â  Â  for idx, row in target_df.iterrows():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  base_time = parse_to_datetime(row["æŠ•ç¨¿æ™‚é–“"])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  name_norm = normalize_text(row["å¥³ã®å­ã®åå‰"])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  matched_files = [img for img in store_images if (name_norm in normalize_text(img.split('/')[-1]) or normalize_text(img.split('/')[-1]) in name_norm) and is_time_match(base_time, img.split('/')[-1])]

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.container():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"#### ğŸ‘¤ {row['å¥³ã®å­ã®åå‰']} / â° {row['æŠ•ç¨¿æ™‚é–“']}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  col_txt, col_img, col_ops = st.columns([2.5, 1, 1])

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with col_txt:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_title = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", row["ã‚¿ã‚¤ãƒˆãƒ«"], key=f"ti_{idx}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_body = st.text_area("æœ¬æ–‡", row["æœ¬æ–‡"], key=f"bo_{idx}", height=400)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ğŸ’¾ å†…å®¹ã‚’ä¿å­˜", key=f"sv_{idx}", type="primary"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws = GC.open_by_key(SHEET_ID).worksheet(SHEET_MAP[sel_acc])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.update_cell(row['__row__'], 6, new_title)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ws.update_cell(row['__row__'], 7, new_body)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.toast(f"{row['å¥³ã®å­ã®åå‰']} ã®æ—¥è¨˜ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ˆåæ˜ ã«ã¯æ›´æ–°ãƒœã‚¿ãƒ³ãŒå¿…è¦ã§ã™ï¼‰")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with col_img:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if matched_files:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for m_path in matched_files:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.image(get_cached_url(m_path), use_container_width=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.popover("ğŸ—‘ï¸ å‰Šé™¤"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("å®Ÿè¡Œã™ã‚‹", key=f"del_{idx}_{m_path}"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bucket.blob(m_path).delete()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error("ğŸš¨ ç”»åƒãªã—")

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with col_ops:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  up_file = st.file_uploader("ğŸ“¥ ç”»åƒè¿½åŠ ", type=["jpg","png","jpeg"], key=f"up_{idx}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if up_file:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ğŸš€ ã‚¢ãƒƒãƒ—", key=f"u_btn_{idx}"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ext = up_file.name.split('.')[-1]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  folder_name = f"ãƒ‡ãƒªã˜ã‚ƒ {sel_store}" if row["åª’ä½“"] == "ãƒ‡ãƒªã˜ã‚ƒ" else sel_store
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_blob_name = f"{sel_area}/{folder_name}/{row['æŠ•ç¨¿æ™‚é–“']}_{row['å¥³ã®å­ã®åå‰']}.{ext}"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  blob = bucket.blob(new_blob_name)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  blob.upload_from_string(up_file.getvalue(), content_type=up_file.type)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("<div class='diary-divider'></div>", unsafe_allow_html=True)

    
    with tab2:
        st.markdown("## ğŸ“Š åº—èˆ—ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³")
        
        combined_data = []
        acc_summary = {}; acc_counts = {}
        try:
            for opt in ACCOUNT_OPTIONS:
                rows = get_full_sheet_data(SHEET_ID, SHEET_MAP[opt])
                if rows and len(rows) > 1:
                    for i, r in enumerate(rows[1:]):
                        if any(str(c).strip() for c in r[:7]):
                            combined_data.append([opt, i+2] + [r[j] if j<len(r) else "" for j in range(7)])
                            a, s, m = str(r[0]).strip(), str(r[1]).strip(), str(r[2]).strip()
                            acc_counts[opt] = acc_counts.get(opt, 0) + 1
                            if opt not in acc_summary: acc_summary[opt] = {}
                            if a not in acc_summary[opt]: acc_summary[opt][a] = set()
                            acc_summary[opt][a].add(f"{m} : {s}")
        except: pass

        if combined_data:
            for acc_code in ACCOUNT_OPTIONS:
                count = acc_counts.get(acc_code, 0)
                st.markdown(f"### ğŸ‘¤ æŠ•ç¨¿{acc_code}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ `{count} ä»¶`")
                if acc_code in acc_summary:
                    areas = acc_summary[acc_code]
                    area_cols = st.columns(len(areas) if len(areas) > 0 else 1)
                    for idx, (area_name, shops) in enumerate(areas.items()):
                        with area_cols[idx]:
                            st.info(f"ğŸ“ **{area_name}**")
                            for shop in sorted(shops):
                                st.checkbox(f"{shop}", key=f"move_{acc_code}_{area_name}_{shop}")
            
            selected_shops = [
                {"acc": k.split('_')[1], "area": k.split('_')[2], "shop": k.split('_')[3].split(" : ")[-1]}
                for k, v in st.session_state.items() if k.startswith("move_") and v
            ]

            if selected_shops:
                if st.button("ğŸš€ é¸æŠã—ãŸåº—èˆ—ã‚’ã€è½ã¡åº—ã€‘ã¸ç§»å‹•ã™ã‚‹", type="primary", use_container_width=True):
                    st.session_state.confirm_move = True

                if st.session_state.get("confirm_move"):
                    st.error("â— æœ¬å½“ã«å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ")
                    col_yes, col_no = st.columns(2)
                    if col_no.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                        st.session_state.confirm_move = False
                        st.rerun()

                    if col_yes.button("â­• ã¯ã„ã€å®Ÿè¡Œã—ã¾ã™", type="primary", use_container_width=True):
                        import time
                        try:
                            sh_stock = GC.open_by_key("1e-iLey43A1t0bIBoijaXP55t5fjONdb0ODiTS53beqM")
                            ws_stock = sh_stock.sheet1
                            for item in selected_shops:
                                ws_main = GC.open_by_key(SHEET_ID).worksheet(SHEET_MAP[item['acc']])
                                main_data = ws_main.get_all_values()
                                for row_idx in range(len(main_data), 0, -1):
                                    row = main_data[row_idx-1]
                                    if len(row) >= 2 and row[1] == item['shop']:
                                        ws_stock.append_row([None, None, row[5], row[6]], value_input_option='USER_ENTERED')
                                        time.sleep(2.0)
                                        ws_main.delete_rows(row_idx)
                                status_sprs = GC.open_by_key(ACCOUNT_STATUS_SHEET_ID)
                                ws_link = status_sprs.worksheet(SHEET_MAP[item['acc']])
                                link_data = ws_link.get_all_values()
                                for row_idx in range(len(link_data), 0, -1):
                                    if len(link_data[row_idx-1]) >= 2 and link_data[row_idx-1][1] == item['shop']:
                                        ws_link.delete_rows(row_idx)
                                        break
                                bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
                                found_blobs = []
                                for pfx in [f"{item['area']}/{item['shop']}/", f"{item['area']}/ãƒ‡ãƒªã˜ã‚ƒ {item['shop']}/"]:
                                    blobs = list(bucket.list_blobs(prefix=pfx))
                                    if blobs: found_blobs = blobs; break
                                for b in found_blobs:
                                    file_name = b.name.split('/')[-1]
                                    new_name = f"ã€è½ã¡åº—ã€‘/{item['shop']}/{file_name}"
                                    bucket.copy_blob(b, bucket, new_name)
                                    b.delete()
                            
                            st.success("ğŸ‰ ç§»å‹•å®Œäº†ï¼ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã«ã™ã‚‹ã«ã¯æ›´æ–°ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
                            st.session_state.confirm_move = False
                        except Exception as e:
                            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()



