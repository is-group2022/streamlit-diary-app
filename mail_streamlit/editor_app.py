import streamlit as st
import pandas as pd
import gspread
import datetime
import urllib.parse
import re
from google.cloud import storage

# --- 1. è¨­å®š ---
SHEET_ID = st.secrets["google_resources"]["spreadsheet_id"]
GCS_BUCKET_NAME = "auto-poster-images"

# --- 2. è£œåŠ©é–¢æ•° (ãƒãƒƒãƒãƒ³ã‚°ã®æ ¸) ---

def normalize_time(t_str):
    """'00:48' ã‚„ '0048' ã‚’ timeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›"""
    t_str = re.sub(r'[^0-9]', '', str(t_str))
    if len(t_str) == 3: t_str = "0" + t_str
    if len(t_str) == 4:
        return datetime.datetime.strptime(t_str, "%H%M")
    return None

def is_time_in_range(base_time, target_str, window_min=20):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã®å…ˆé ­æ•°å­—ãŒ base_time ã®Â±20åˆ†ä»¥å†…ã‹åˆ¤å®š"""
    target_num = re.match(r'^(\d{3,4})', target_str)
    if not target_num: return False
    
    try:
        t_target = normalize_time(target_num.group(1))
        if not t_target or not base_time: return False
        
        # æ—¥ä»˜ã‚’å›ºå®šã—ã¦å·®åˆ†ã‚’è¨ˆç®—
        diff = abs((base_time - t_target).total_seconds()) / 60
        # æ·±å¤œã®è·¨ãã‚’è€ƒæ…® (23:55 ã¨ 00:05 ãªã©)
        return diff <= window_min or diff >= (1440 - window_min)
    except:
        return False

def get_cached_url(blob_name):
    safe_path = urllib.parse.quote(blob_name)
    return f"https://storage.googleapis.com/{GCS_BUCKET_NAME}/{safe_path}"

# --- 3. APIé€£æº ---
@st.cache_resource(ttl=3600)
def get_clients():
    gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
    gcs = storage.Client.from_service_account_info(st.secrets["gcp_service_account"])
    return gc, gcs

GC, GCS_CLIENT = get_clients()
SPRS = GC.open_by_key(SHEET_ID)

# --- 4. UI ---
st.set_page_config(layout="wide", page_title="é«˜åº¦ãªãƒãƒƒãƒãƒ³ã‚°ç·¨é›†")

def main():
    st.title("ğŸ” é«˜åº¦ãªæ—¥è¨˜Ã—ç”»åƒãƒãƒƒãƒãƒ³ã‚°")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    all_ws = SPRS.worksheets()
    target_sheets = ["æŠ•ç¨¿Aã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "æŠ•ç¨¿Bã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "æŠ•ç¨¿Cã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "æŠ•ç¨¿Dã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"]
    all_rows = []
    for ws in all_ws:
        if ws.title in target_sheets:
            data = ws.get_all_values()
            if len(data) > 1:
                tmp_df = pd.DataFrame(data[1:], columns=data[0][:7])
                tmp_df['__sheet__'] = ws.title
                tmp_df['__row__'] = range(2, len(data) + 1)
                all_rows.append(tmp_df)
    
    if not all_rows: return
    full_df = pd.concat(all_rows)

    # é¸æŠUI
    areas = sorted(full_df["ã‚¨ãƒªã‚¢"].unique())
    c1, c2 = st.columns(2)
    sel_area = c1.selectbox("ğŸ“ ã‚¨ãƒªã‚¢", ["æœªé¸æŠ"] + areas)
    
    if sel_area != "æœªé¸æŠ":
        stores = sorted(full_df[full_df["ã‚¨ãƒªã‚¢"] == sel_area]["åº—å"].unique())
        sel_store = c2.selectbox("ğŸ¢ åº—èˆ—", ["æœªé¸æŠ"] + stores)

        if sel_store != "æœªé¸æŠ":
            target_df = full_df[(full_df["ã‚¨ãƒªã‚¢"] == sel_area) & (full_df["åº—å"] == sel_store)]
            media = target_df.iloc[0]["åª’ä½“"]
            
            # GCSã‚¹ã‚­ãƒ£ãƒ³ (ãƒ‡ãƒªã˜ã‚ƒã®ã‚¹ãƒšãƒ¼ã‚¹æ›–æ˜§å›é¿)
            bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
            # å…¨ä»¶å–å¾—ã—ã¦Pythonå´ã§æ­£è¦åŒ–ãƒãƒƒãƒãƒ³ã‚°
            prefix = f"{sel_area}/"
            blobs = list(bucket.list_blobs(prefix=prefix))
            
            # ãƒ•ã‚©ãƒ«ãƒ€åã®åˆ¤å®šç”¨(ã‚¹ãƒšãƒ¼ã‚¹ãƒ»å…¨è§’åŠè§’ã‚’ç„¡è¦–)
            def normalize_name(s): return re.sub(r'\s+', '', s).replace('ã€€','')

            target_store_norm = normalize_name(sel_store)
            if media == "ãƒ‡ãƒªã˜ã‚ƒ":
                target_store_norm = normalize_name(f"ãƒ‡ãƒªã˜ã‚ƒ{sel_store}")

            # è©²å½“åº—èˆ—ã®ç”»åƒã ã‘æŠ½å‡º
            store_images = []
            for b in blobs:
                parts = b.name.split('/')
                if len(parts) >= 3:
                    folder_part = normalize_name(parts[1])
                    if folder_part == target_store_norm:
                        store_images.append(b.name)

            # è¡¨ç¤º
            for idx, row in target_df.iterrows():
                base_time = normalize_time(row["æŠ•ç¨¿æ™‚é–“"])
                girl_name = normalize_name(row["å¥³ã®å­ã®åå‰"])
                
                # ç”»åƒæ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯
                # 1. åå‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ (å…¨è§’åŠè§’ç„¡è¦–)
                # 2. æ™‚é–“ãŒÂ±20åˆ†ä»¥å†…ã‹
                matches = []
                for img_path in store_images:
                    img_file = normalize_name(img_path.split('/')[-1])
                    if girl_name in img_file and is_time_in_range(base_time, img_file):
                        matches.append(img_path)

                with st.container(border=True):
                    col_info, col_edit, col_img = st.columns([1, 2, 1])
                    with col_info:
                        st.write(f"â° {row['æŠ•ç¨¿æ™‚é–“']} / ğŸ‘¤ {row['å¥³ã®å­ã®åå‰']}")
                        if matches: st.success("âœ… ãƒãƒƒãƒ")
                        else: st.error("ğŸš¨ ç”»åƒä¸åœ¨")
                    
                    with col_edit:
                        t = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", row["ã‚¿ã‚¤ãƒˆãƒ«"], key=f"t_{idx}")
                        b = st.text_area("æœ¬æ–‡", row["æœ¬æ–‡"], key=f"b_{idx}")
                        if st.button("æ›´æ–°", key=f"s_{idx}"):
                            ws = SPRS.worksheet(row['__sheet__'])
                            ws.update_cell(row['__row__'], 6, t)
                            ws.update_cell(row['__row__'], 7, b)
                            st.rerun()

                    with col_img:
                        for m in matches:
                            st.image(get_cached_url(m))
                            st.caption(m.split('/')[-1])

if __name__ == "__main__":
    main()
