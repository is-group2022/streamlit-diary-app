import streamlit as st
import pandas as pd
import gspread
import datetime
import urllib.parse
import re
from google.cloud import storage

# --- 1. å®šæ•°ãƒ»è¨­å®š ---
try:
    SHEET_ID = st.secrets["google_resources"]["spreadsheet_id"]
    GCS_BUCKET_NAME = "auto-poster-images"
    ACCOUNT_OPTIONS = ["A", "B", "C", "D"]
    SHEET_MAP = {opt: f"æŠ•ç¨¿{opt}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ" for opt in ACCOUNT_OPTIONS}
    DF_COLS = ["ã‚¨ãƒªã‚¢", "åº—å", "åª’ä½“", "æŠ•ç¨¿æ™‚é–“", "å¥³ã®å­ã®åå‰", "ã‚¿ã‚¤ãƒˆãƒ«", "æœ¬æ–‡"]
except KeyError:
    st.error("ğŸš¨ secrets.tomlã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- 2. è£œåŠ©é–¢æ•° ---
def normalize_text(s):
    if not s: return ""
    return re.sub(r'\s+', '', str(s)).replace('ã€€', '').lower()

def parse_to_datetime(t_str):
    t_clean = re.sub(r'[^0-9]', '', str(t_str))
    if len(t_clean) == 3: t_clean = "0" + t_clean
    if len(t_clean) == 4:
        try: return datetime.datetime.strptime(t_clean, "%H%M")
        except: return None
    return None

def is_time_match(base_time, target_filename, window_min=20):
    if not base_time: return False
    match = re.match(r'^(\d{3,4})', target_filename)
    if not match: return False
    t_target = parse_to_datetime(match.group(1))
    if not t_target: return False
    diff = abs((base_time - t_target).total_seconds()) / 60
    return diff <= window_min or diff >= (1440 - window_min)

def get_cached_url(blob_name):
    return f"https://storage.googleapis.com/{GCS_BUCKET_NAME}/{urllib.parse.quote(blob_name)}"

# --- 3. APIæ¥ç¶š ---
@st.cache_resource(ttl=3600)
def get_clients():
    gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
    gcs = storage.Client.from_service_account_info(st.secrets["gcp_service_account"])
    return gc, gcs

GC, GCS_CLIENT = get_clients()
SPRS = GC.open_by_key(SHEET_ID)

# --- 4. UIæ§‹ç¯‰ ---
st.set_page_config(layout="wide", page_title="å†™ãƒ¡æ—¥è¨˜ã‚¨ãƒ‡ã‚£ã‚¿")

# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆã‚«ãƒ¼ãƒ‰ã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆåŒ–ã¨ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ï¼‰
st.markdown("""
    <style>
    .main { background-color: #f0f2f6; }
    [data-testid="stHeader"] { display: none; }
    .diary-container {
        background-color: white;
        border-radius: 8px;
        padding: 15px;
        margin-bottom: 10px;
        border: 1px solid #e0e0e0;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
    }
    .stTextArea textarea { font-size: 14px; line-height: 1.4; }
    .stMetric { background-color: white; border: 1px solid #e0e0e0; border-radius: 8px; padding: 10px; }
    </style>
""", unsafe_allow_html=True)

def main():
    st.title("ğŸ“¸ å†™ãƒ¡æ—¥è¨˜ã‚¨ãƒ‡ã‚£ã‚¿ Pro")
    
    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼é¸æŠ ---
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        sel_acc = st.radio("ğŸ‘¤ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", ACCOUNT_OPTIONS, horizontal=True)
        
        ws = SPRS.worksheet(SHEET_MAP[sel_acc])
        data = ws.get_all_values()
        if len(data) <= 1:
            st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
            
        full_df = pd.DataFrame(data[1:])
        full_df = full_df.iloc[:, :7]
        while full_df.shape[1] < 7: full_df[full_df.shape[1]] = ""
        full_df.columns = DF_COLS
        full_df['__row__'] = range(2, len(data) + 1)

        areas = sorted(full_df["ã‚¨ãƒªã‚¢"].unique())
        sel_area = st.selectbox("ğŸ“ ã‚¨ãƒªã‚¢", ["æœªé¸æŠ"] + areas)
        
        sel_store = "æœªé¸æŠ"
        if sel_area != "æœªé¸æŠ":
            stores = sorted(full_df[full_df["ã‚¨ãƒªã‚¢"] == sel_area]["åº—å"].unique())
            sel_store = st.selectbox("ğŸ¢ åº—èˆ—", ["æœªé¸æŠ"] + stores)

    if sel_store == "æœªé¸æŠ":
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ»ã‚¨ãƒªã‚¢ãƒ»åº—èˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
    target_df = full_df[(full_df["ã‚¨ãƒªã‚¢"] == sel_area) & (full_df["åº—å"] == sel_store)]
    
    # ãƒ¡ãƒˆãƒªãƒƒã‚¯è¡¨ç¤º
    m_c1, m_c2, m_c3 = st.columns([1,1,2])
    m_c1.metric("Total", f"{len(target_df)} ä»¶")
    m_c2.metric("Shop", sel_store)
    m_c3.write("") # ã‚¹ãƒšãƒ¼ã‚¹ç”¨

    # GCSç”»åƒå–å¾—
    bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
    blobs = list(bucket.list_blobs(prefix=f"{sel_area}/"))
    store_norm = normalize_text(sel_store)
    store_images = [b.name for b in blobs if normalize_text(b.name.split('/')[1]) in [store_norm, normalize_text(f"ãƒ‡ãƒªã˜ã‚ƒ{sel_store}")]]

    st.write("---")

    # --- æ—¥è¨˜ãƒªã‚¹ãƒˆè¡¨ç¤º ---
    for idx, row in target_df.iterrows():
        base_time = parse_to_datetime(row["æŠ•ç¨¿æ™‚é–“"])
        name_norm = normalize_text(row["å¥³ã®å­ã®åå‰"])
        
        # ç”»åƒãƒãƒƒãƒ
        matched_files = [img for img in store_images if name_norm in normalize_text(img.split('/')[-1]) and is_time_match(base_time, img.split('/')[-1])]

        # 1ä»¶ã”ã¨ã®å¤–æ 
        with st.container():
            st.markdown(f"**ğŸ‘¤ {row['å¥³ã®å­ã®åå‰']} / â° {row['æŠ•ç¨¿æ™‚é–“']}**")
            
            # 3ã‚«ãƒ©ãƒ æ§‹æˆï¼šâ‘ ãƒ†ã‚­ã‚¹ãƒˆç·¨é›† â‘¡ç”»åƒè¡¨ç¤º â‘¢æ“ä½œ
            col_txt, col_img, col_ops = st.columns([2.5, 1, 1])

            with col_txt:
                new_title = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", row["ã‚¿ã‚¤ãƒˆãƒ«"], key=f"ti_{idx}", label_visibility="collapsed")
                new_body = st.text_area("æœ¬æ–‡", row["æœ¬æ–‡"], key=f"bo_{idx}", height=80, label_visibility="collapsed")
                if st.button("ğŸ’¾ æ–‡è¨€ã‚’ä¿å­˜", key=f"sv_{idx}"):
                    ws.update_cell(row['__row__'], 6, new_title)
                    ws.update_cell(row['__row__'], 7, new_body)
                    st.toast("ä¿å­˜å®Œäº†ï¼")

            with col_img:
                if matched_files:
                    for m_path in matched_files:
                        st.image(get_cached_url(m_path), use_container_width=True)
                        # å‰Šé™¤ç¢ºèªï¼ˆãƒãƒƒãƒ—ã‚ªãƒ¼ãƒãƒ¼ï¼‰
                        with st.popover("ğŸ—‘ï¸ å‰Šé™¤"):
                            st.write("æœ¬å½“ã«ã“ã®ç”»åƒã‚’å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ")
                            if st.button("ã¯ã„ã€å‰Šé™¤ã—ã¾ã™", key=f"real_del_{idx}_{m_path}", type="primary"):
                                bucket.blob(m_path).delete()
                                st.cache_data.clear()
                                st.rerun()
                else:
                    st.caption("ğŸš¨ ç”»åƒãªã—")

            with col_ops:
                up_file = st.file_uploader("ğŸ“¥ å…¥ã‚Œæ›¿ãˆ/è¿½åŠ ", type=["jpg","png","jpeg"], key=f"up_{idx}", label_visibility="collapsed")
                if up_file:
                    if st.button("ğŸš€ Up", key=f"u_btn_{idx}"):
                        ext = up_file.name.split('.')[-1]
                        folder_name = f"ãƒ‡ãƒªã˜ã‚ƒ {sel_store}" if row["åª’ä½“"] == "ãƒ‡ãƒªã˜ã‚ƒ" else sel_store
                        new_blob_name = f"{sel_area}/{folder_name}/{row['æŠ•ç¨¿æ™‚é–“']}_{row['å¥³ã®å­ã®åå‰']}.{ext}"
                        blob = bucket.blob(new_blob_name)
                        blob.upload_from_string(up_file.getvalue(), content_type=up_file.type)
                        st.cache_data.clear()
                        st.rerun()
            
            st.markdown("<hr style='margin: 10px 0; border: none; border-top: 1px solid #eee;'>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()
