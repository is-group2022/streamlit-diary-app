import streamlit as st
import pandas as pd
import gspread
import datetime
import urllib.parse
import re
from google.cloud import storage
from io import BytesIO

# --- 1. å®šæ•°ãƒ»è¨­å®š ---
try:
    SHEET_ID = st.secrets["google_resources"]["spreadsheet_id"]
    GCS_BUCKET_NAME = "auto-poster-images"
    ACCOUNT_OPTIONS = ["A", "B", "C", "D"]
    SHEET_MAP = {opt: f"æŠ•ç¨¿{opt}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ" for opt in ACCOUNT_OPTIONS}
    DF_COLS = ["ã‚¨ãƒªã‚¢", "åº—å", "åª’ä½“", "æŠ•ç¨¿æ™‚é–“", "å¥³ã®å­ã®åå‰", "ã‚¿ã‚¤ãƒˆãƒ«", "æœ¬æ–‡"]
except KeyError:
    st.error("ğŸš¨ secrets.tomlã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- 2. è£œåŠ©é–¢æ•° ---
def normalize_text(s):
    if not s: return ""
    return re.sub(r'\s+', '', str(s)).replace('ã€€', '').lower()

def parse_to_datetime(t_str):
    t_clean = re.sub(r'[^0-9]', '', str(t_str))
    if len(t_clean) == 3: t_clean = "0" + t_clean
    if len(t_clean) == 4:
        try: return datetime.datetime.strptime(t_clean, "%H%M")
        except: return None
    return None

def is_time_match(base_time, target_filename, window_min=20):
    if not base_time: return False
    match = re.match(r'^(\d{3,4})', target_filename)
    if not match: return False
    t_target = parse_to_datetime(match.group(1))
    if not t_target: return False
    diff = abs((base_time - t_target).total_seconds()) / 60
    return diff <= window_min or diff >= (1440 - window_min)

def get_cached_url(blob_name):
    return f"https://storage.googleapis.com/{GCS_BUCKET_NAME}/{urllib.parse.quote(blob_name)}"

# --- 3. APIæ¥ç¶š ---
@st.cache_resource(ttl=3600)
def get_clients():
    gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
    gcs = storage.Client.from_service_account_info(st.secrets["gcp_service_account"])
    return gc, gcs

GC, GCS_CLIENT = get_clients()
SPRS = GC.open_by_key(SHEET_ID)

# --- 4. UIæ§‹ç¯‰ ---
st.set_page_config(layout="wide", page_title="å†™ãƒ¡æ—¥è¨˜ãƒ»é«˜åº¦ç·¨é›†ã‚¨ãƒ‡ã‚£ã‚¿")

# ãƒ‡ã‚¶ã‚¤ãƒ³CSS
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stMetric { background-color: white; padding: 15px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    [data-testid="stHeader"] { display: none; }
    .stButton button { width: 100%; }
    .diary-card { border: 1px solid #ddd; padding: 20px; border-radius: 10px; margin-bottom: 20px; background-color: white; }
    </style>
""", unsafe_allow_html=True)

def main():
    st.title("ğŸ“¸ å†™ãƒ¡æ—¥è¨˜ãƒ»é«˜åº¦ç·¨é›†ã‚¨ãƒ‡ã‚£ã‚¿")
    
    # --- ã‚µã‚¤ãƒ‰ãƒãƒ¼: é¸æŠãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ ---
    with st.sidebar:
        st.header("ğŸ›  é¸æŠãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        sel_acc = st.selectbox("ğŸ‘¤ æŠ•ç¨¿ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", ACCOUNT_OPTIONS)
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        ws = SPRS.worksheet(SHEET_MAP[sel_acc])
        data = ws.get_all_values()
        if len(data) <= 1:
            st.warning("ã“ã®ã‚·ãƒ¼ãƒˆã«ã¯ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
            
        full_df = pd.DataFrame(data[1:])
        full_df = full_df.iloc[:, :7]
        while full_df.shape[1] < 7: full_df[full_df.shape[1]] = ""
        full_df.columns = DF_COLS
        full_df['__row__'] = range(2, len(data) + 1)

        areas = sorted(full_df["ã‚¨ãƒªã‚¢"].unique())
        sel_area = st.selectbox("ğŸ“ ã‚¨ãƒªã‚¢ã‚’é¸æŠ", ["æœªé¸æŠ"] + areas)
        
        if sel_area != "æœªé¸æŠ":
            stores = sorted(full_df[full_df["ã‚¨ãƒªã‚¢"] == sel_area]["åº—å"].unique())
            sel_store = st.selectbox("ğŸ¢ åº—èˆ—ã‚’é¸æŠ", ["æœªé¸æŠ"] + stores)
        else:
            sel_store = "æœªé¸æŠ"

    if sel_store == "æœªé¸æŠ":
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œã‚¢ã‚«ã‚¦ãƒ³ãƒˆã€ã€Œã‚¨ãƒªã‚¢ã€ã€Œåº—èˆ—ã€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    # --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è¡¨ç¤º ---
    target_df = full_df[(full_df["ã‚¨ãƒªã‚¢"] == sel_area) & (full_df["åº—å"] == sel_store)]
    total_count = len(target_df)

    # çµ±è¨ˆè¡¨ç¤º
    c_m1, c_m2, c_m3 = st.columns(3)
    c_m1.metric("åˆè¨ˆä»¶æ•°", f"{total_count} ä»¶")
    c_m2.metric("ã‚¨ãƒªã‚¢", sel_area)
    c_m3.metric("åº—èˆ—", sel_store)

    # GCSç”»åƒã‚¹ã‚­ãƒ£ãƒ³
    bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
    blobs = list(bucket.list_blobs(prefix=f"{sel_area}/"))
    store_norm = normalize_text(sel_store)
    store_images = [b.name for b in blobs if normalize_text(b.name.split('/')[1]) in [store_norm, normalize_text(f"ãƒ‡ãƒªã˜ã‚ƒ{sel_store}")]]

    st.divider()

    # --- æ—¥è¨˜ãƒªã‚¹ãƒˆã®ãƒ«ãƒ¼ãƒ— ---
    for idx, row in target_df.iterrows():
        base_time = parse_to_datetime(row["æŠ•ç¨¿æ™‚é–“"])
        name_norm = normalize_text(row["å¥³ã®å­ã®åå‰"])
        
        # ç”»åƒç…§åˆ
        matched_files = [img for img in store_images if name_norm in normalize_text(img.split('/')[-1]) and is_time_match(base_time, img.split('/')[-1])]

        with st.container():
            st.markdown(f"### {row['å¥³ã®å­ã®åå‰']} ({row['æŠ•ç¨¿æ™‚é–“']})")
            col_txt, col_img_manage = st.columns([2, 1])

            with col_txt:
                new_title = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", row["ã‚¿ã‚¤ãƒˆãƒ«"], key=f"ti_{idx}")
                new_body = st.text_area("æœ¬æ–‡", row["æœ¬æ–‡"], key=f"bo_{idx}", height=150)
                if st.button("ğŸ“ æ—¥è¨˜æ–‡ã‚’æ›´æ–°", key=f"btn_up_{idx}", type="primary"):
                    ws.update_cell(row['__row__'], 6, new_title)
                    ws.update_cell(row['__row__'], 7, new_body)
                    st.success("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°ã—ã¾ã—ãŸï¼")

            with col_img_manage:
                st.write("**ğŸ–¼ ç”»åƒç®¡ç†**")
                if matched_files:
                    for m_path in matched_files:
                        st.image(get_cached_url(m_path), use_container_width=True)
                        if st.button(f"ğŸ—‘ ã“ã®ç”»åƒã‚’å‰Šé™¤", key=f"del_{idx}_{m_path}"):
                            bucket.blob(m_path).delete()
                            st.cache_data.clear()
                            st.rerun()
                else:
                    st.error("ğŸš¨ ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                # ç”»åƒå…¥ã‚Œæ›¿ãˆãƒ»è¿½åŠ æ©Ÿèƒ½
                up_file = st.file_uploader("ğŸ“¥ ç”»åƒã‚’å…¥ã‚Œæ›¿ãˆ/è¿½åŠ ", type=["jpg","png","jpeg"], key=f"up_{idx}")
                if up_file:
                    if st.button("ğŸš€ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", key=f"btn_upimg_{idx}"):
                        # æ—¢å­˜ç”»åƒãŒã‚ã‚‹å ´åˆã¯ä¸Šæ›¸ãã§ã¯ãªãè¿½åŠ ï¼ˆæ—¢å­˜ç”»åƒã‚’æ¶ˆã—ãŸã„å ´åˆã¯å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™é‹ç”¨ï¼‰
                        ext = up_file.name.split('.')[-1]
                        folder_name = f"ãƒ‡ãƒªã˜ã‚ƒ {sel_store}" if row["åª’ä½“"] == "ãƒ‡ãƒªã˜ã‚ƒ" else sel_store
                        # ä¿å­˜åã¯ æŠ•ç¨¿æ™‚é–“_åå‰.æ‹¡å¼µå­
                        new_blob_name = f"{sel_area}/{folder_name}/{row['æŠ•ç¨¿æ™‚é–“']}_{row['å¥³ã®å­ã®åå‰']}.{ext}"
                        blob = bucket.blob(new_blob_name)
                        blob.upload_from_string(up_file.getvalue(), content_type=up_file.type)
                        st.success("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
                        st.cache_data.clear()
                        st.rerun()
            st.divider()

if __name__ == "__main__":
    main()
