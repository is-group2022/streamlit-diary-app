import streamlit as st
import pandas as pd
import gspread
import datetime
import urllib.parse
import re
from google.oauth2.service_account import Credentials
from google.cloud import storage

# --- 1. è¨­å®šã¨å®šæ•° ---
try:
    SHEET_ID = st.secrets["google_resources"]["spreadsheet_id"]
    GCS_BUCKET_NAME = "auto-poster-images"
    POSTING_ACCOUNT_SHEETS = ["æŠ•ç¨¿Aã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "æŠ•ç¨¿Bã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "æŠ•ç¨¿Cã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "æŠ•ç¨¿Dã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"]
    # å‡¦ç†ã«ä½¿ç”¨ã™ã‚‹æœ€åˆã®7åˆ—
    DF_COLS = ["ã‚¨ãƒªã‚¢", "åº—å", "åª’ä½“", "æŠ•ç¨¿æ™‚é–“", "å¥³ã®å­ã®åå‰", "ã‚¿ã‚¤ãƒˆãƒ«", "æœ¬æ–‡"]
except KeyError:
    st.error("ğŸš¨ secrets.tomlã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# --- 2. è£œåŠ©é–¢æ•° ---

def normalize_text(s):
    """ã‚¹ãƒšãƒ¼ã‚¹ãƒ»å…¨è§’ãƒ»å¤§æ–‡å­—å°æ–‡å­—ã®å·®ã‚’ãªãã™"""
    if not s: return ""
    return re.sub(r'\s+', '', str(s)).replace('ã€€', '').lower()

def parse_to_datetime(t_str):
    """æ™‚é–“æ–‡å­—åˆ—ã‚’è¨ˆç®—å¯èƒ½ãªå‹ã«å¤‰æ›"""
    t_clean = re.sub(r'[^0-9]', '', str(t_str))
    if len(t_clean) == 3: t_clean = "0" + t_clean
    if len(t_clean) == 4:
        try:
            return datetime.datetime.strptime(t_clean, "%H%M")
        except:
            return None
    return None

def is_time_match(base_time, target_filename, window_min=20):
    """ãƒ•ã‚¡ã‚¤ãƒ«åã®å…ˆé ­æ•°å­—ãŒÂ±20åˆ†ä»¥å†…ã‹åˆ¤å®š"""
    if not base_time: return False
    match = re.match(r'^(\d{3,4})', target_filename)
    if not match: return False
    
    t_target = parse_to_datetime(match.group(1))
    if not t_target: return False
    
    diff = abs((base_time - t_target).total_seconds()) / 60
    return diff <= window_min or diff >= (1440 - window_min)

def get_cached_url(blob_name):
    safe_path = urllib.parse.quote(blob_name)
    return f"https://storage.googleapis.com/{GCS_BUCKET_NAME}/{safe_path}"

# --- 3. APIé€£æº ---
@st.cache_resource(ttl=3600)
def get_clients():
    gc = gspread.service_account_from_dict(st.secrets["gcp_service_account"])
    gcs = storage.Client.from_service_account_info(st.secrets["gcp_service_account"])
    return gc, gcs

try:
    GC, GCS_CLIENT = get_clients()
    SPRS = GC.open_by_key(SHEET_ID)
except Exception as e:
    st.error(f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# --- 4. UI ---
st.set_page_config(layout="wide", page_title="æ—¥è¨˜Ã—ç”»åƒ ç…§åˆã‚¨ãƒ‡ã‚£ã‚¿")
st.markdown("<style>header[data-testid='stHeader'] { display: none !important; }</style>", unsafe_allow_html=True)

def main():
    st.title("ğŸ“ æ—¥è¨˜Ã—ç”»åƒ ãƒãƒƒãƒãƒ³ã‚°ç·¨é›†éƒ¨")

    # --- ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ ---
    all_rows = []
    with st.spinner("ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ä¸­..."):
        for s_name in POSTING_ACCOUNT_SHEETS:
            try:
                ws = SPRS.worksheet(s_name)
                data = ws.get_all_values()
                if len(data) > 1:
                    rows = data[1:]
                    # åˆ—æ•°ãŒãƒãƒ©ãƒãƒ©ã§ã‚‚å¯¾å¿œã§ãã‚‹ã‚ˆã†ã«ä¸€åº¦DataFrameåŒ–
                    tmp_df = pd.DataFrame(rows)
                    
                    # ğŸ’¡ 8åˆ—ç›®ï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰ä»¥é™ã‚’åˆ‡ã‚Šæ¨ã¦ã€æœ€åˆã®7åˆ—ã ã‘ã‚’ç¢ºå®Ÿã«å–å¾—
                    tmp_df = tmp_df.iloc[:, :7]
                    
                    # åˆ—æ•°ãŒ7ã«æº€ãŸãªã„å ´åˆã®ä¿é™º
                    while tmp_df.shape[1] < 7:
                        tmp_df[tmp_df.shape[1]] = ""
                    
                    tmp_df.columns = DF_COLS
                    tmp_df['__sheet__'] = s_name
                    tmp_df['__row__'] = range(2, len(data) + 1)
                    all_rows.append(tmp_df)
            except: continue

    if not all_rows:
        st.warning("è¡¨ç¤ºã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    full_df = pd.concat(all_rows)

    # ãƒ•ã‚£ãƒ«ã‚¿UI
    c1, c2 = st.columns(2)
    areas = sorted(full_df["ã‚¨ãƒªã‚¢"].unique())
    selected_area = c1.selectbox("ğŸ“ ã‚¨ãƒªã‚¢ã‚’é¸æŠ", ["æœªé¸æŠ"] + areas)
    if selected_area == "æœªé¸æŠ": return

    stores = sorted(full_df[full_df["ã‚¨ãƒªã‚¢"] == selected_area]["åº—å"].unique())
    selected_store = c2.selectbox("ğŸ¢ åº—èˆ—ã‚’é¸æŠ", ["æœªé¸æŠ"] + stores)
    if selected_store == "æœªé¸æŠ": return

    # åº—èˆ—ãƒ‡ãƒ¼ã‚¿ã¨GCSç”»åƒå–å¾—
    target_df = full_df[(full_df["ã‚¨ãƒªã‚¢"] == selected_area) & (full_df["åº—å"] == selected_store)]
    
    bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
    blobs = list(bucket.list_blobs(prefix=f"{selected_area}/"))
    
    store_norm = normalize_text(selected_store)
    media_type = target_df.iloc[0]["åª’ä½“"]

    store_images = []
    for b in blobs:
        parts = b.name.split('/')
        if len(parts) >= 3:
            folder_part_norm = normalize_text(parts[1])
            if folder_part_norm in [store_norm, normalize_text(f"ãƒ‡ãƒªã˜ã‚ƒ{selected_store}")]:
                store_images.append(b.name)

    st.divider()

    # --- ãƒ¡ã‚¤ãƒ³è¡¨ç¤º ---
    for idx, row in target_df.iterrows():
        base_time = parse_to_datetime(row["æŠ•ç¨¿æ™‚é–“"])
        girl_name_norm = normalize_text(row["å¥³ã®å­ã®åå‰"])
        
        # ç”»åƒç…§åˆãƒ­ã‚¸ãƒƒã‚¯
        matched_files = [
            img for img in store_images 
            if girl_name_norm in normalize_text(img.split('/')[-1]) and is_time_match(base_time, img.split('/')[-1])
        ]

        with st.container(border=True):
            col_info, col_edit, col_img = st.columns([1, 2, 1])
            
            with col_info:
                st.write(f"**â° {row['æŠ•ç¨¿æ™‚é–“']}**")
                st.write(f"**ğŸ‘¤ {row['å¥³ã®å­ã®åå‰']}**")
                if matched_files:
                    st.success(f"âœ… ä¸€è‡´ ({len(matched_files)}æš)")
                else:
                    st.error("ğŸš¨ ç”»åƒãªã—")
                    st.caption(f"æ¡ä»¶: {row['æŠ•ç¨¿æ™‚é–“']} Â±20åˆ†")

            with col_edit:
                new_title = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«", value=row["ã‚¿ã‚¤ãƒˆãƒ«"], key=f"ti_{idx}")
                new_body = st.text_area("æœ¬æ–‡", value=row["æœ¬æ–‡"], key=f"bo_{idx}", height=120)
                
                if st.button("ğŸ’¾ ã“ã®å†…å®¹ã§æ›´æ–°", key=f"btn_{idx}"):
                    ws = SPRS.worksheet(row['__sheet__'])
                    # Fåˆ—(6), Gåˆ—(7)ã‚’æ›´æ–°ã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹(8)ã¯è§¦ã‚‰ãªã„ã€‚
                    ws.update_cell(row['__row__'], 6, new_title)
                    ws.update_cell(row['__row__'], 7, new_body)
                    st.success("æ›´æ–°ã—ã¾ã—ãŸï¼")
                    st.cache_data.clear()

            with col_img:
                if matched_files:
                    for m in matched_files:
                        st.image(get_cached_url(m), use_container_width=True)
                        st.caption(m.split('/')[-1])
                else:
                    st.info("ä¸ä¸€è‡´")

if __name__ == "__main__":
    main()
