import streamlit as st
import pandas as pd
import gspread
import zipfile
import re
from io import BytesIO
from google.oauth2.service_account import Credentials
from google.cloud import storage 
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload

# --- 1. å®šæ•°ã¨åˆæœŸè¨­å®š ---
try:
    SHEET_ID = st.secrets["google_resources"]["spreadsheet_id"] 
    ACCOUNT_STATUS_SHEET_ID = "1_GmWjpypap4rrPGNFYWkwcQE1SoK3QOMJlozEhkBwVM"
    USABLE_DIARY_SHEET_ID = "1e-iLey43A1t0bIBoijaXP55t5fjONdb0ODiTS53beqM"
    
    GCS_BUCKET_NAME = "auto-poster-images"

    SHEET_NAMES = st.secrets["sheet_names"]
    POSTING_ACCOUNT_SHEETS = {
        "A": "æŠ•ç¨¿Aã‚¢ã‚«ã‚¦ãƒ³ãƒˆ",
        "B": "æŠ•ç¨¿Bã‚¢ã‚«ã‚¦ãƒ³ãƒˆ",
        "C": "æŠ•ç¨¿Cã‚¢ã‚«ã‚¦ãƒ³ãƒˆ",
        "D": "æŠ•ç¨¿Dã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"
    }
    
    USABLE_DIARY_SHEET = "ã€ä½¿ç”¨å¯èƒ½æ—¥è¨˜æ–‡ã€‘"
    MEDIA_OPTIONS = ["é§…ã¡ã‹", "ãƒ‡ãƒªã˜ã‚ƒ"]
    POSTING_ACCOUNT_OPTIONS = ["A", "B", "C", "D"] 
    
    SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/cloud-platform']
except KeyError:
    st.error("ğŸš¨ secrets.tomlã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

REGISTRATION_HEADERS = ["ã‚¨ãƒªã‚¢", "åº—å", "åª’ä½“", "æŠ•ç¨¿æ™‚é–“", "å¥³ã®å­ã®åå‰", "ã‚¿ã‚¤ãƒˆãƒ«", "æœ¬æ–‡"]
INPUT_HEADERS = ["æŠ•ç¨¿æ™‚é–“", "å¥³ã®å­ã®åå‰", "ã‚¿ã‚¤ãƒˆãƒ«", "æœ¬æ–‡"]

# --- 2. å„ç¨®APIé€£æº (ä¿®æ­£æ¸ˆã¿ï¼šGCã‚’å®šç¾©) ---
@st.cache_resource(ttl=3600)
def get_gspread_client():
    return gspread.service_account_from_dict(st.secrets["gcp_service_account"])

@st.cache_resource(ttl=3600)
def get_gcs_client():
    return storage.Client.from_service_account_info(st.secrets["gcp_service_account"])

try:
    GC = get_gspread_client()  # ä¸å‹•ç”£å±‹ï¼ˆClientï¼‰
    SPRS = GC.open_by_key(SHEET_ID)  # å®¶1ï¼ˆSpreadsheetï¼‰
    STATUS_SPRS = GC.open_by_key(ACCOUNT_STATUS_SHEET_ID)  # å®¶2ï¼ˆSpreadsheetï¼‰
    GCS_CLIENT = get_gcs_client()
except Exception as e:
    st.error(f"âŒ APIæ¥ç¶šå¤±æ•—: {e}"); st.stop()

def gcs_upload_wrapper(uploaded_file, entry, area, store):
    try:
        bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
        folder_name = f"ãƒ‡ãƒªã˜ã‚ƒ {store}" if st.session_state.global_media == "ãƒ‡ãƒªã˜ã‚ƒ" else store
        ext = uploaded_file.name.split('.')[-1]
        blob_path = f"{area}/{folder_name}/{entry['æŠ•ç¨¿æ™‚é–“'].strip()}_{entry['å¥³ã®å­ã®åå‰'].strip()}.{ext}"
        blob = bucket.blob(blob_path)
        blob.upload_from_string(uploaded_file.getvalue(), content_type=uploaded_file.type)
        return True
    except Exception as e:
        st.error(f"âŒ GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return False

@st.cache_data(ttl=600)
def get_cached_url(blob_name):
    bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
    blob = bucket.blob(blob_name)
    return blob.generate_signed_url(version="v4", expiration=600, method="GET")

# --- 3. UI æ§‹ç¯‰ ---
st.set_page_config(layout="wide", page_title="å†™ãƒ¡æ—¥è¨˜æŠ•ç¨¿ç®¡ç†")

st.markdown("""
    <style>
    .block-container { padding-top: 0rem !important; padding-bottom: 0rem !important; }
    header[data-testid="stHeader"] { display: none !important; }
    .stTabs [data-baseweb="tab-list"] { gap: 10px; height: 80px; }
    button[data-baseweb="tab"] {
        font-size: 32px !important; font-weight: 800 !important; height: 70px !important;
        padding: 0px 30px !important; background-color: #f0f2f6 !important;
        border-radius: 10px 10px 0px 0px !important; margin-right: 5px !important;
    }
    button[data-baseweb="tab"][aria-selected="true"] {
        color: white !important; background-color: #FF4B4B !important;
    }
    .sticky-header-row {
        position: -webkit-sticky;
        position: sticky;
        top: 0px;
        z-index: 1000;
        background-color: white !important;
        padding: 10px 0px;
        margin-bottom: 5px;
    }
    </style>
""", unsafe_allow_html=True)

if 'diary_entries' not in st.session_state:
    st.session_state.diary_entries = [{h: "" for h in INPUT_HEADERS} for _ in range(40)]

# ã‚¿ãƒ–æ§‹æˆã®æ›´æ–°
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ“ â‘  ãƒ‡ãƒ¼ã‚¿ç™»éŒ²", 
    "ğŸ“Š â‘¡ åº—èˆ—ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³", 
    "ğŸ“‚ â‘¢ æŠ•ç¨¿æ—¥è¨˜æ–‡ç®¡ç†", 
    "ğŸ“¸ â‘£ æŠ•ç¨¿ç”»åƒç®¡ç†",
    "ğŸ“š â‘¤ ä½¿ç”¨å¯èƒ½æ—¥è¨˜æ–‡",
    "ğŸ–¼ â‘¥ ä½¿ç”¨å¯èƒ½ç”»åƒ"
])

combined_data = []
acc_summary = {}; acc_counts = {}
try:
    all_ws = SPRS.worksheets()
    ws_dict = {ws.title: ws for ws in all_ws}
    for code, s_name in POSTING_ACCOUNT_SHEETS.items():
        if s_name in ws_dict:
            rows = ws_dict[s_name].get_all_values()
            if len(rows) > 1:
                for i, r in enumerate(rows[1:]):
                    if any(str(c).strip() for c in r[:7]):
                        combined_data.append([code, i+2] + [r[j] if j<len(r) else "" for j in range(7)])
                        a, s, m = str(r[0]).strip(), str(r[1]).strip(), str(r[2]).strip()
                        acc_counts[code] = acc_counts.get(code, 0) + 1
                        if code not in acc_summary: acc_summary[code] = {}
                        if a not in acc_summary[code]: acc_summary[code][a] = set()
                        acc_summary[code][a].add(f"{m} : {s}")
except: pass

# --- Tab 1 ---
with tab1:
    st.header("1ï¸âƒ£ æ–°è¦ãƒ‡ãƒ¼ã‚¿ç™»éŒ²")
    
    # åŸºæœ¬æƒ…å ±
    c1, c2, c3, c4 = st.columns(4)
    target_acc = c1.selectbox("ğŸ‘¤ æŠ•ç¨¿ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", POSTING_ACCOUNT_OPTIONS, key="sel_acc_1")
    st.session_state.global_media = c2.selectbox("ğŸŒ åª’ä½“", MEDIA_OPTIONS, key="sel_media_1")
    global_area = c3.text_input("ğŸ“ ã‚¨ãƒªã‚¢", key="in_area_1")
    global_store = c4.text_input("ğŸ¢ åº—å", key="in_store_1")
    
    st.subheader("ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±")
    c5, c6 = st.columns(2)
    login_id = c5.text_input("ID", key="login_id")
    login_pw = c6.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", key="login_pw")
    
    st.markdown("---")
    st.subheader("ğŸ“¸ æŠ•ç¨¿å†…å®¹å…¥åŠ›")

    # ãƒ˜ãƒƒãƒ€ãƒ¼å›ºå®šè¡¨ç¤ºï¼ˆHTMLï¼‰
    st.markdown("""
        <div style="display: flex; flex-direction: row; border-bottom: 2px solid #444; background-color: #f0f2f6; padding: 10px; border-radius: 5px 5px 0 0;">
            <div style="flex: 1; font-weight: bold;">æ™‚é–“</div>
            <div style="flex: 1; font-weight: bold;">åå‰</div>
            <div style="flex: 2; font-weight: bold;">ã‚¿ã‚¤ãƒˆãƒ«</div>
            <div style="flex: 3; font-weight: bold;">æœ¬æ–‡</div>
            <div style="flex: 2; font-weight: bold;">ç”»åƒ</div>
        </div>
    """, unsafe_allow_html=True)

    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã®ç”Ÿæˆï¼ˆ40è¡Œï¼‰
    # å¤§é‡å…¥åŠ›æ™‚ã®è² è·ã‚’ä¸‹ã’ã‚‹ãŸã‚ã€keyç®¡ç†ã‚’å¾¹åº•
    for i in range(40):
        cols = st.columns([1, 1, 2, 3, 2])
        st.session_state.diary_entries[i]['æŠ•ç¨¿æ™‚é–“'] = cols[0].text_input(f"t{i}", key=f"t_{i}", label_visibility="collapsed")
        st.session_state.diary_entries[i]['å¥³ã®å­ã®åå‰'] = cols[1].text_input(f"n{i}", key=f"n_{i}", label_visibility="collapsed")
        st.session_state.diary_entries[i]['ã‚¿ã‚¤ãƒˆãƒ«'] = cols[2].text_area(f"ti{i}", key=f"ti_{i}", height=68, label_visibility="collapsed")
        st.session_state.diary_entries[i]['æœ¬æ–‡'] = cols[3].text_area(f"b{i}", key=f"b_{i}", height=68, label_visibility="collapsed")
        st.session_state.diary_entries[i]['img'] = cols[4].file_uploader(f"g{i}", key=f"img_{i}", label_visibility="collapsed")

    if st.button("ğŸ”¥ ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã™ã‚‹", type="primary", use_container_width=True):
        # å…¥åŠ›ãƒã‚§ãƒƒã‚¯
        valid_data = [e for e in st.session_state.diary_entries if e['æŠ•ç¨¿æ™‚é–“'] and e['å¥³ã®å­ã®åå‰']]
        if not valid_data:
            st.error("æŠ•ç¨¿æ™‚é–“ã¨åå‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            st.stop()
        
        if not global_area or not global_store:
            st.error("ã‚¨ãƒªã‚¢ã¨åº—åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            st.stop()

        progress_text = st.empty()
        try:
            # 1. ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            progress_text.info("ğŸ“¸ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
            for e in valid_data:
                if e['img']:
                    gcs_upload_wrapper(e['img'], e, global_area, global_store)
            
            # 2. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼ˆæ—¥è¨˜æ–‡ï¼‰ä¸€æ‹¬ç™»éŒ²
            progress_text.info("ğŸ“ æ—¥è¨˜æ–‡ã‚’ç™»éŒ²ä¸­...")
            sheet_name = POSTING_ACCOUNT_SHEETS[target_acc]
            
            # APIã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã‚·ãƒ¼ãƒˆå–å¾—ã‚’æ…é‡ã«è¡Œã†
            try:
                ws_main = SPRS.worksheet(sheet_name)
            except Exception as e:
                st.error(f"ã‚·ãƒ¼ãƒˆ '{sheet_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ã‚¿ãƒ–åã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                st.stop()
                
            rows_main = [[global_area, global_store, st.session_state.global_media, e['æŠ•ç¨¿æ™‚é–“'], e['å¥³ã®å­ã®åå‰'], e['ã‚¿ã‚¤ãƒˆãƒ«'], e['æœ¬æ–‡']] for e in valid_data]
            ws_main.append_rows(rows_main, value_input_option='USER_ENTERED')
            
            # 3. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹/ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ï¼‰ç™»éŒ²
            progress_text.info("ğŸ” ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’ç™»éŒ²ä¸­...")
            ws_status = STATUS_SPRS.worksheet(sheet_name)
            ws_status.append_row([global_area, global_store, st.session_state.global_media, login_id, login_pw], value_input_option='USER_ENTERED')
            
            progress_text.empty()
            st.success(f"âœ… {len(valid_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«ç™»éŒ²ã—ã¾ã—ãŸï¼")
            
            # ç™»éŒ²å¾Œã€å…¥åŠ›ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãŸã‚ã«ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆä»»æ„ï¼‰
            # st.rerun()

        except Exception as e:
            st.error(f"APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ç½®ã„ã¦å†åº¦è©¦ã—ã¦ãã ã•ã„ã€‚è©³ç´°: {e}")
            
# =========================================================
# --- Tab 2: ğŸ“Š å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåº—èˆ—ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³ (ä¿®æ­£ç‰ˆ) ---
# =========================================================
with tab2:
    st.markdown("## ğŸ“Š åº—èˆ—ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³")
    if combined_data:
        for acc_code in POSTING_ACCOUNT_OPTIONS:
            count = acc_counts.get(acc_code, 0)
            st.markdown(f"### ğŸ‘¤ æŠ•ç¨¿{acc_code}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ `{count} ä»¶`")
            if acc_code in acc_summary:
                areas = acc_summary[acc_code]
                area_cols = st.columns(len(areas) if len(areas) > 0 else 1)
                for idx, (area_name, shops) in enumerate(areas.items()):
                    with area_cols[idx]:
                        st.info(f"ğŸ“ **{area_name}**")
                        for shop in sorted(shops):
                            st.checkbox(f"{shop}", key=f"move_{acc_code}_{area_name}_{shop}")
        
        selected_shops = [
            {"acc": k.split('_')[1], "area": k.split('_')[2], "shop": k.split('_')[3].split(" : ")[-1]}
            for k, v in st.session_state.items() if k.startswith("move_") and v
        ]

        if selected_shops:
            st.warning(f"âš ï¸ ç¾åœ¨ {len(selected_shops)} åº—èˆ—ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã™ã€‚")
            if st.button("ğŸš€ é¸æŠã—ãŸåº—èˆ—ã‚’ã€è½ã¡åº—ã€‘ã¸ç§»å‹•ã™ã‚‹", type="primary", use_container_width=True):
                st.session_state.confirm_move = True

            # æœ€çµ‚ãƒã‚§ãƒƒã‚¯ç”»é¢
            if st.session_state.get("confirm_move"):
                st.error("â— æœ¬å½“ã«å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿæ—¥è¨˜ã¨ç”»åƒãŒç§»å‹•ã•ã‚Œã¾ã™ã€‚")
                col_yes, col_no = st.columns(2)
                
                # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒœã‚¿ãƒ³ã®å¾©æ´»
                if col_no.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                    st.session_state.confirm_move = False
                    st.rerun()

                if col_yes.button("â­• ã¯ã„ã€å®Ÿè¡Œã—ã¾ã™", type="primary", use_container_width=True):
                    import time  # ã‚¨ãƒ©ãƒ¼å›é¿
                    progress_bar = st.progress(0)
                    
                    try:
                        # æŒ‡å®šã•ã‚ŒãŸæ—¥è¨˜ä¿å­˜ç”¨ã‚·ãƒ¼ãƒˆã‚’é–‹ã
                        sh_stock = GC.open_by_key("1e-iLey43A1t0bIBoijaXP55t5fjONdb0ODiTS53beqM")
                        ws_stock = sh_stock.sheet1
                        sh_link = GC.open_by_key(ACCOUNT_STATUS_SHEET_ID)
                        
                        for i, item in enumerate(selected_shops):
                            # â‘  æ—¥è¨˜ç§»å‹•ï¼ˆA, Båˆ—ã‚’ç©ºã«ã™ã‚‹ï¼‰
                            ws_main = SPRS.worksheet(POSTING_ACCOUNT_SHEETS[item['acc']])
                            main_data = ws_main.get_all_values()
                            
                            # è©²å½“åº—èˆ—ã®å…¨æ—¥è¨˜ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ç§»å‹•
                            for row_idx in range(len(main_data), 0, -1):
                                row = main_data[row_idx-1]
                                if len(row) >= 2 and row[1] == item['shop']:
                                    # Aåˆ—(ã‚¨ãƒªã‚¢)ã¨Båˆ—(åº—å)ã‚’ç©ºæ–‡å­—ã«ã—ã¦ã€Fåˆ—(ã‚¿ã‚¤ãƒˆãƒ«)ã¨Gåˆ—(æœ¬æ–‡)ã‚’ç™»éŒ²
                                    # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®æ§‹é€ ã«åˆã‚ã›ã¦ ["", "", "", "", "", ã‚¿ã‚¤ãƒˆãƒ«, æœ¬æ–‡]
                                    ws_stock.append_row(["", "", "", "", "", row[5], row[6]])
                                    time.sleep(0.5)
                                    ws_main.delete_rows(row_idx)

                            # â‘¡ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆç´ä»˜ã‘ï¼ˆãƒªãƒ³ã‚¯ï¼‰å‰Šé™¤
                            ws_link = sh_link.worksheet(POSTING_ACCOUNT_SHEETS[item['acc']])
                            link_data = ws_link.get_all_values()
                            for row_idx in range(len(link_data), 0, -1):
                                if len(link_data[row_idx-1]) >= 2 and link_data[row_idx-1][1] == item['shop']:
                                    ws_link.delete_rows(row_idx)
                                    break
                            
                            # â‘¢ GCSç”»åƒç§»å‹•ï¼ˆä¿®æ­£ç‰ˆï¼‰
                            bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
                            # ã€Œãƒ‡ãƒªã˜ã‚ƒã€å¯¾å¿œã®ãƒ•ã‚©ãƒ«ãƒ€åä½œæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å†ç¾
                            folder_name = f"ãƒ‡ãƒªã˜ã‚ƒ {item['shop']}" if st.session_state.get('global_media') == "ãƒ‡ãƒªã˜ã‚ƒ" else item['shop']
                            prefix = f"{item['area']}/{folder_name}/"
                            
                            blobs = list(bucket.list_blobs(prefix=prefix))
                            for b in blobs:
                                # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«åã ã‘ã‚’æŠ½å‡ºã—ã¦æ–°ã—ã„ãƒ‘ã‚¹ï¼ˆè½ã¡åº—ç”¨ï¼‰ã‚’ä½œæˆ
                                file_name = b.name.split('/')[-1]
                                new_name = f"ã€è½ã¡åº—ã€‘/{item['shop']}/{file_name}"
                                
                                bucket.copy_blob(b, bucket, new_name)
                                b.delete()
                            
                            progress_bar.progress((i + 1) / len(selected_shops))
                        
                        st.success("ğŸ‰ æ—¥è¨˜ï¼ˆA,Båˆ—ç©ºæ¬„ï¼‰ãŠã‚ˆã³ç”»åƒã®ç§»å‹•ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                        st.session_state.confirm_move = False
                        st.cache_data.clear()
                        time.sleep(1)
                        st.rerun()

                    except Exception as e:
                        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                        st.session_state.confirm_move = False
        
# =========================================================
# --- Tab 3: ğŸ“‚ æŠ•ç¨¿æ—¥è¨˜æ–‡ç®¡ç† (å¤‰æ›´æ¤œçŸ¥ãƒ»è‡ªå‹•ã‚½ãƒ¼ãƒˆç‰ˆ) ---
# =========================================================
with tab3:
    st.markdown("### ğŸ“‚ æŠ•ç¨¿æ—¥è¨˜æ–‡ç®¡ç† (ä¸€æ‹¬ç·¨é›†)")
    st.caption("â€»å†…å®¹ã‚’å¤‰æ›´ã™ã‚‹ã¨è‡ªå‹•çš„ã«æœ€ä¸Šéƒ¨ã¸ç§»å‹•ã—ã€èµ¤ãå¼·èª¿ã•ã‚Œã¾ã™ã€‚")

    if combined_data:
        # 1. å…ƒãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
        df_orig = pd.DataFrame(combined_data, columns=["ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "è¡Œç•ªå·"] + REGISTRATION_HEADERS)
        
        # 2. æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿æ©Ÿèƒ½
        c_search1, c_search2 = st.columns([1, 2])
        filter_acc = c_search1.multiselect("ğŸ‘¤ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§çµã‚Šè¾¼ã¿", POSTING_ACCOUNT_OPTIONS, key="filter_acc_3")
        filter_text = c_search2.text_input("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ (åº—åãƒ»åå‰ãªã©)", key="filter_text_3")

        # 3. ç·¨é›†ç”¨ãƒ‡ãƒ¼ã‚¿ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        if 'edited_df_3' not in st.session_state:
            st.session_state.edited_df_3 = df_orig.copy()

        working_df = st.session_state.edited_df_3.copy()

        # 4. å¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
        # å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒã—ã¦1ç®‡æ‰€ã§ã‚‚é•ãˆã° True
        diff_mask = (working_df != df_orig).any(axis=1)
        working_df.insert(0, "çŠ¶æ…‹", diff_mask.map({True: "ğŸ”´ å¤‰æ›´ã‚ã‚Š", False: "ãƒ¼"}))

        # 5. ã‚½ãƒ¼ãƒˆï¼ˆå¤‰æ›´ã‚ã‚Šã‚’ä¸€ç•ªä¸Šã€æ¬¡ã«ã‚¢ã‚«ã‚¦ãƒ³ãƒˆé †ï¼‰
        working_df = working_df.sort_values(by=["çŠ¶æ…‹", "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"], ascending=[False, True])

        # 6. ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
        if filter_acc:
            working_df = working_df[working_df["ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"].isin(filter_acc)]
        if filter_text:
            working_df = working_df[working_df.astype(str).apply(lambda x: filter_text.lower() in x.str.lower().any(), axis=1)]

        # 7. è¡¨ç¤ºã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ï¼ˆå¤‰æ›´ç®‡æ‰€ã®è¡Œã‚’èµ¤ãã™ã‚‹ï¼‰
        def highlight_changes(row):
            if row["çŠ¶æ…‹"] == "ğŸ”´ å¤‰æ›´ã‚ã‚Š":
                return ['background-color: #ffebee; color: #b71c1c; font-weight: bold'] * len(row)
            return [''] * len(row)

        styled_df = working_df.style.apply(highlight_changes, axis=1)

        # 8. ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿
        new_edited_df = st.data_editor(
            styled_df,
            key="main_editor_3",
            use_container_width=True,
            hide_index=True,
            disabled=["çŠ¶æ…‹", "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "è¡Œç•ªå·"],
            height=600
        )

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®æ›´æ–°ï¼ˆå†æç”»æ™‚ã«å¤‰æ›´ã‚’ç¶­æŒã™ã‚‹ãŸã‚ï¼‰
        # â€» st.data_editor ã®æˆ»ã‚Šå€¤ã‹ã‚‰ã€ŒçŠ¶æ…‹ã€åˆ—ã‚’é™¤ã„ã¦ä¿å­˜
        st.session_state.edited_df_3 = new_edited_df.drop(columns=["çŠ¶æ…‹"])

        # 9. ä¿å­˜å‡¦ç†
        c_save1, c_save2 = st.columns([4, 1])
        if c_save2.button("ğŸ”¥ ä¸€æ‹¬ä¿å­˜", type="primary", use_container_width=True):
            changed_rows = new_edited_df[new_edited_df["çŠ¶æ…‹"] == "ğŸ”´ å¤‰æ›´ã‚ã‚Š"]
            
            if changed_rows.empty:
                st.warning("å¤‰æ›´ã•ã‚ŒãŸç®‡æ‰€ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                with st.spinner("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°ä¸­..."):
                    try:
                        for acc_code in POSTING_ACCOUNT_OPTIONS:
                            acc_changes = changed_rows[changed_rows["ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"] == acc_code]
                            if acc_changes.empty: continue
                            
                            ws = SPRS.worksheet(POSTING_ACCOUNT_SHEETS[acc_code])
                            for _, row in acc_changes.iterrows():
                                row_idx = int(row["è¡Œç•ªå·"])
                                # ä¿å­˜æ™‚ã¯å…ƒã®ãƒ˜ãƒƒãƒ€ãƒ¼é †ã«ä¸¦ã¹æ›¿ãˆ
                                update_values = [str(row[h]) for h in REGISTRATION_HEADERS]
                                ws.update(f"A{row_idx}:G{row_idx}", [update_values], value_input_option='USER_ENTERED')
                        
                        st.success(f"ğŸ‰ {len(changed_rows)}ä»¶ã®å¤‰æ›´ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼")
                        # ä¿å­˜å¾Œã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªã‚¢ã—ã¦æœ€æ–°åŒ–
                        if 'edited_df_3' in st.session_state: del st.session_state.edited_df_3
                        st.rerun()
                    except Exception as e:
                        st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

        if c_save1.button("ğŸ”„ ç·¨é›†ã‚’ãƒªã‚»ãƒƒãƒˆ", use_container_width=False):
            if 'edited_df_3' in st.session_state: del st.session_state.edited_df_3
            st.rerun()

    else:
        st.info("ç·¨é›†å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
# =========================================================
# --- Tab 4: ğŸ“¸ â‘£ æŠ•ç¨¿ç”»åƒç®¡ç† (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç‰ˆ) ---
# =========================================================
with tab4:
    st.header("ğŸ“¸ æŠ•ç¨¿ç”»åƒç®¡ç†")
    
    # --- 1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥é–¢æ•° ---
    @st.cache_data(ttl=600)
    def get_gcs_hierarchy_v7():
        try:
            b = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
            blobs = GCS_CLIENT.list_blobs(GCS_BUCKET_NAME, prefix="", delimiter='/')
            list(blobs)
            areas = [p.replace("/", "") for p in blobs.prefixes if "ã€è½ã¡åº—ã€‘" not in p and p != "/"]
            hierarchy = {}
            for area in areas:
                area_blobs = GCS_CLIENT.list_blobs(GCS_BUCKET_NAME, prefix=f"{area}/", delimiter='/')
                list(area_blobs)
                hierarchy[area] = [p for p in area_blobs.prefixes]
            return hierarchy
        except: return {}

    @st.cache_data(ttl=300)
    def get_image_list_cached_v7(path):
        b = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
        blobs = list(b.list_blobs(prefix=path))
        return [bl.name for bl in blobs if bl.name != path and bl.name.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]

    hierarchy = get_gcs_hierarchy_v7()

    if hierarchy:
        c_sel1, c_sel2 = st.columns(2)
        selected_area = c_sel1.selectbox("ğŸ“ ã‚¨ãƒªã‚¢", ["é¸æŠã—ã¦ãã ã•ã„"] + list(hierarchy.keys()), key="sel_area_4")
        
        if selected_area != "é¸æŠã—ã¦ãã ã•ã„":
            store_paths = hierarchy[selected_area]
            store_options = {p.split('/')[-2]: p for p in store_paths}
            selected_store_name = c_sel2.selectbox("ğŸ¢ åº—èˆ—", ["é¸æŠã—ã¦ãã ã•ã„"] + list(store_options.keys()), key="sel_store_4")

            if selected_store_name != "é¸æŠã—ã¦ãã ã•ã„":
                target_path = store_options[selected_store_name]
                active_bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)

                # --- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
                with st.expander("â• ç”»åƒã‚’ã“ã®åº—èˆ—ã«è¿½åŠ ", expanded=False):
                    up_files = st.file_uploader("ç”»åƒã‚’ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True, type=["jpg","jpeg","png","webp"], key="up4_v7")
                    if st.button("ğŸš€ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹", use_container_width=True):
                        if up_files:
                            for f in up_files:
                                active_bucket.blob(f"{target_path}{f.name}").upload_from_string(f.getvalue(), content_type=f.type)
                            st.cache_data.clear(); st.rerun()

                st.markdown("---")

                # --- æ¤œç´¢ã¨æ“ä½œ ---
                img_names = get_image_list_cached_v7(target_path)
                
                if img_names:
                    search_query = st.text_input("ğŸ” åå‰ã§æ¤œç´¢", key="search_4_v7")
                    display_names = [n for n in img_names if search_query.lower() in n.split('/')[-1].lower()]

                    btn_c1, btn_c2, btn_c3, btn_c4 = st.columns([1, 1, 2, 2])
                    if btn_c1.button("âœ… å…¨é¸æŠ", use_container_width=True):
                        for n in display_names: st.session_state[f"del_4_{n}"] = True
                        st.rerun()
                    if btn_c2.button("â¬œï¸ è§£é™¤", use_container_width=True):
                        for n in display_names: st.session_state[f"del_4_{n}"] = False
                        st.rerun()

                    selected_items = [n for n in display_names if st.session_state.get(f"del_4_{n}")]

                    # --- ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ ---
                    if selected_items:
                        if len(selected_items) == 1:
                            # 1æšãªã‚‰ã€Œç”Ÿã€ã§ä¿å­˜
                            path = selected_items[0]
                            file_name = path.split('/')[-1]
                            btn_c3.download_button(
                                label="ğŸ’¾ 1æšã‚’ä¿å­˜",
                                data=active_bucket.blob(path).download_as_bytes(),
                                file_name=file_name,
                                use_container_width=True,
                                type="primary"
                            )
                        else:
                            # è¤‡æ•°ãªã‚‰ã€ŒZIPã€ã§ä¿å­˜
                            zip_buf = BytesIO()
                            with zipfile.ZipFile(zip_buf, "w") as zf:
                                for path in selected_items:
                                    zf.writestr(f"{selected_store_name}/{path.split('/')[-1]}", active_bucket.blob(path).download_as_bytes())
                            btn_c3.download_button(
                                label=f"â¬‡ï¸ {len(selected_items)}æšã‚’ZIPä¿å­˜",
                                data=zip_buf.getvalue(),
                                file_name=f"{selected_store_name}.zip",
                                use_container_width=True,
                                type="primary"
                            )

                        # --- å‰Šé™¤ç¢ºèª ---
                        if btn_c4.button(f"ğŸ—‘ {len(selected_items)}æšã‚’å‰Šé™¤", use_container_width=True, type="secondary"):
                            st.session_state.confirm_del_4 = True

                        if st.session_state.get("confirm_del_4"):
                            st.error(f"âš ï¸ é¸æŠã—ãŸ {len(selected_items)} æšã‚’æœ¬å½“ã«å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ")
                            conf_c1, conf_c2 = st.columns(2)
                            if conf_c1.button("â­• å‰Šé™¤å®Ÿè¡Œ", type="primary", use_container_width=True):
                                for n in selected_items: active_bucket.blob(n).delete()
                                st.session_state.confirm_del_4 = False
                                st.cache_data.clear(); st.rerun()
                            if conf_c2.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                                st.session_state.confirm_del_4 = False
                                st.rerun()

                    st.markdown(f"**è¡¨ç¤ºä¸­: {len(display_names)} æš**")
                    
                    # --- ç”»åƒã‚°ãƒªãƒƒãƒ‰è¡¨ç¤º ---
                    cols = st.columns(8)
                    for idx, b_name in enumerate(display_names):
                        with cols[idx % 8]:
                            short_name = b_name.split('/')[-1]
                            st.image(get_cached_url(b_name), use_container_width=True)
                            # ç”»åƒåã‚’è¡¨ç¤ºï¼ˆè¦‹ã‚„ã™ãæ”¹è¡Œå¯¾å¿œï¼‰
                            st.caption(short_name)
                            st.checkbox("é¸", key=f"del_4_{b_name}", label_visibility="collapsed")
                else:
                    st.info("ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

# --- Tab 5 ---
with tab5:
    st.header("5ï¸âƒ£ ä½¿ç”¨å¯èƒ½æ—¥è¨˜æ–‡")
    try:
        tmp_sprs = connect_to_gsheets(USABLE_DIARY_SHEET_ID)
        tmp_ws = tmp_sprs.worksheet("ã€ä½¿ç”¨å¯èƒ½æ—¥è¨˜æ–‡ã€‘")
        tmp_data = tmp_ws.get_all_values()
        if len(tmp_data) > 1:
            st.dataframe(pd.DataFrame(tmp_data[1:], columns=tmp_data[0]), use_container_width=True, height=600)
    except Exception as e: st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# =========================================================
# --- Tab 6: ğŸ–¼ â‘¥ ä½¿ç”¨å¯èƒ½ç”»åƒï¼ˆè½ã¡åº—ï¼‰ é«˜é€Ÿç‰ˆ ---
# =========================================================
with tab6:
    st.header("ğŸ–¼ ä½¿ç”¨å¯èƒ½ç”»åƒãƒ–ãƒ©ã‚¦ã‚¶ï¼ˆè½ã¡åº—ï¼‰")
    
    ROOT_PATH = "ã€è½ã¡åº—ã€‘/"
    
    # è½ã¡åº—å°‚ç”¨ã®ç”»åƒãƒªã‚¹ãƒˆå–å¾—ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    @st.cache_data(ttl=300)
    def get_ochimise_images_cached(prefix, recursive=False):
        b = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
        # recursive=Trueã®å ´åˆã¯delimiterã‚’æŒ‡å®šã›ãšå…¨å–å¾—ã€Falseã®å ´åˆã¯æŒ‡å®š
        if recursive:
            blobs = list(b.list_blobs(prefix=prefix))
        else:
            blobs = list(b.list_blobs(prefix=prefix, delimiter='/'))
        return [bl.name for bl in blobs if bl.name != prefix and bl.name.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]

    # 1. ãƒ¢ãƒ¼ãƒ‰é¸æŠã¨ãƒ•ã‚©ãƒ«ãƒ€å–å¾—
    try:
        bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
        blobs_init = GCS_CLIENT.list_blobs(GCS_BUCKET_NAME, prefix=ROOT_PATH, delimiter='/')
        list(blobs_init)
        folders = blobs_init.prefixes
    except: folders = []

    show_all = st.checkbox("ğŸ“‚ å…¨ç”»åƒè¡¨ç¤ºï¼ˆå…¨ã¦ã®åº—èˆ—ã‚’ã¾ã¨ã‚ã¦è¡¨ç¤ºï¼‰", key="show_all_ochimise")

    target_images = []
    current_label = "è½ã¡åº—"

    if show_all:
        # å…¨è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰
        target_images = get_ochimise_images_cached(ROOT_PATH, recursive=True)
        current_label = "å…¨åº—èˆ—ä¸€æ‹¬"
    elif folders:
        # åº—èˆ—é¸æŠãƒ¢ãƒ¼ãƒ‰
        folder_opts = {f.replace(ROOT_PATH, "").replace("/", ""): f for f in folders}
        selected_key = st.selectbox("ğŸ“ åº—èˆ—ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ", ["é¸æŠã—ã¦ãã ã•ã„"] + list(folder_opts.keys()), key="sel_ochimise_folder")
        if selected_key != "é¸æŠã—ã¦ãã ã•ã„":
            target_path = folder_opts[selected_key]
            target_images = get_ochimise_images_cached(target_path, recursive=False)
            current_label = selected_key

    # 2. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¨ãƒªã‚¢
    if target_images:
        st.markdown("---")
        
        # æ¤œç´¢ãƒãƒ¼
        search_q = st.text_input("ğŸ” åå‰ã§æ¤œç´¢ (è½ã¡åº—å†…)", key="search_6")
        display_imgs = [n for n in target_images if search_q.lower() in n.split('/')[-1].lower()]

        # æ“ä½œãƒœã‚¿ãƒ³
        c1, c2, c3, c4 = st.columns([1, 1, 2, 2])
        if c1.button("âœ… å…¨é¸æŠ", key="all_6", use_container_width=True):
            for n in display_imgs: st.session_state[f"sel_6_{n}"] = True
            st.rerun()
        if c2.button("â¬œï¸ è§£é™¤", key="none_6", use_container_width=True):
            for n in display_imgs: st.session_state[f"sel_6_{n}"] = False
            st.rerun()

        selected_items = [n for n in display_imgs if st.session_state.get(f"sel_6_{n}")]

        if selected_items:
            # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            if len(selected_items) == 1:
                path = selected_items[0]
                c3.download_button("ğŸ’¾ 1æšä¿å­˜ã—å‰Šé™¤", data=bucket.blob(path).download_as_bytes(), file_name=path.split('/')[-1], use_container_width=True, type="primary")
            else:
                zip_buf = BytesIO()
                with zipfile.ZipFile(zip_buf, "w") as zf:
                    for path in selected_items:
                        zf.writestr(f"è½ã¡åº—_{current_label}/{path.split('/')[-1]}", bucket.blob(path).download_as_bytes())
                c3.download_button(f"â¬‡ï¸ {len(selected_items)}æšZIPä¿å­˜ã—å‰Šé™¤", data=zip_buf.getvalue(), file_name=f"è½ã¡åº—_{current_label}.zip", use_container_width=True, type="primary")
            
            # å‰Šé™¤ï¼ˆä¿å­˜ã›ãšã«å‰Šé™¤ã—ãŸã„å ´åˆç”¨ï¼‰
            if c4.button(f"ğŸ—‘ {len(selected_items)}æšã‚’å®Œå…¨å‰Šé™¤", use_container_width=True, type="secondary"):
                for n in selected_items: bucket.blob(n).delete()
                st.cache_data.clear(); st.rerun()

        st.write(f"**è¡¨ç¤ºæ•°: {len(display_imgs)}æš**")

        # 3. ç”»åƒã‚°ãƒªãƒƒãƒ‰ï¼ˆ8åˆ—ï¼‰
        cols = st.columns(8)
        for idx, b_name in enumerate(display_imgs):
            with cols[idx % 8]:
                st.image(get_cached_url(b_name), use_container_width=True)
                st.caption(b_name.split('/')[-1])
                st.checkbox("é¸", key=f"sel_6_{b_name}", label_visibility="collapsed")
    else:
        if not show_all: st.info("è¡¨ç¤ºã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else: st.info("ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")















