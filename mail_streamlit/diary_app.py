import streamlit as st
import pandas as pd
import gspread
import zipfile
import re
from io import BytesIO
from datetime import timedelta
from google.oauth2.service_account import Credentials
from google.cloud import storage 
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload

# --- 1. å®šæ•°ã¨åˆæœŸè¨­å®š ---
try:
    SHEET_ID = st.secrets["google_resources"]["spreadsheet_id"] 
    ACCOUNT_STATUS_SHEET_ID = "1_GmWjpypap4rrPGNFYWkwcQE1SoK3QOMJlozEhkBwVM"
    USABLE_DIARY_SHEET_ID = "1e-iLey43A1t0bIBoijaXP55t5fjONdb0ODiTS53beqM"
    
    GCS_BUCKET_NAME = "auto-poster-images"

    SHEET_NAMES = st.secrets["sheet_names"]
    POSTING_ACCOUNT_SHEETS = {
        "A": "æŠ•ç¨¿Aã‚¢ã‚«ã‚¦ãƒ³ãƒˆ",
        "B": "æŠ•ç¨¿Bã‚¢ã‚«ã‚¦ãƒ³ãƒˆ",
        "C": "æŠ•ç¨¿Cã‚¢ã‚«ã‚¦ãƒ³ãƒˆ",
        "D": "æŠ•ç¨¿Dã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"
    }
    
    USABLE_DIARY_SHEET = "ã€ä½¿ç”¨å¯èƒ½æ—¥è¨˜æ–‡ã€‘"
    MEDIA_OPTIONS = ["é§…ã¡ã‹", "ãƒ‡ãƒªã˜ã‚ƒ"]
    POSTING_ACCOUNT_OPTIONS = ["A", "B", "C", "D"] 
    
    SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/cloud-platform']
except KeyError:
    st.error("ğŸš¨ secrets.tomlã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

REGISTRATION_HEADERS = ["ã‚¨ãƒªã‚¢", "åº—å", "åª’ä½“", "æŠ•ç¨¿æ™‚é–“", "å¥³ã®å­ã®åå‰", "ã‚¿ã‚¤ãƒˆãƒ«", "æœ¬æ–‡"]
INPUT_HEADERS = ["æŠ•ç¨¿æ™‚é–“", "å¥³ã®å­ã®åå‰", "ã‚¿ã‚¤ãƒˆãƒ«", "æœ¬æ–‡"]

# --- 2. å„ç¨®APIé€£æº ---
@st.cache_resource(ttl=3600)
def get_gspread_client():
    """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆAPIã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    return gspread.service_account_from_dict(st.secrets["gcp_service_account"])

@st.cache_resource(ttl=3600)
def get_gcs_client():
    """Google Cloud Storageã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ"""
    from google.cloud import storage
    return storage.Client.from_service_account_info(st.secrets["gcp_service_account"])

try:
    # 1. ã¾ãšã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    GC = get_gspread_client()
    GCS_CLIENT = get_gcs_client()
    
    # 2. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã
    SPRS = GC.open_by_key(SHEET_ID)
    STATUS_SPRS = GC.open_by_key(ACCOUNT_STATUS_SHEET_ID)
    
except Exception as e:
    # 429ã‚¨ãƒ©ãƒ¼ï¼ˆåˆ¶é™è¶…éï¼‰ã®å ´åˆã¯å°‚ç”¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    if "429" in str(e):
        st.error("ğŸš¨ Google APIã®åˆ¶é™ã‚’è¶…ãˆã¾ã—ãŸã€‚1åˆ†ã»ã©å¾…ã£ã¦ã‹ã‚‰å†èª­ã¿è¾¼ã¿ã—ã¦ãã ã•ã„ã€‚")
    elif "name 'get_gcs_client'" in str(e):
        st.error("ğŸš¨ é–¢æ•°å®šç¾©ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ä¿®æ­£ã‚³ãƒ¼ãƒ‰ã‚’åæ˜ ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.error(f"âŒ APIæ¥ç¶šå¤±æ•—: {e}")
    st.stop()
    
def gcs_upload_wrapper(uploaded_file, entry, area, store):
    try:
        bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
        folder_name = f"ãƒ‡ãƒªã˜ã‚ƒ {store}" if st.session_state.global_media == "ãƒ‡ãƒªã˜ã‚ƒ" else store
        ext = uploaded_file.name.split('.')[-1]
        blob_path = f"{area}/{folder_name}/{entry['æŠ•ç¨¿æ™‚é–“'].strip()}_{entry['å¥³ã®å­ã®åå‰'].strip()}.{ext}"
        blob = bucket.blob(blob_path)
        blob.upload_from_string(uploaded_file.getvalue(), content_type=uploaded_file.type)
        return True
    except Exception as e:
        st.error(f"âŒ GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return False

@st.cache_data(ttl=86400 * 7)
def get_cached_url(blob_name):
    bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
    blob = bucket.blob(blob_name)
    # timedelta ã ã‘ã§æ›¸ã‘ã‚‹
    return blob.generate_signed_url(expiration=timedelta(days=7))
    
# --- 3. UI æ§‹ç¯‰ ---
st.set_page_config(layout="wide", page_title="å†™ãƒ¡æ—¥è¨˜æŠ•ç¨¿ç®¡ç†")

st.markdown("""
    <style>
    .block-container { padding-top: 0rem !important; padding-bottom: 0rem !important; }
    header[data-testid="stHeader"] { display: none !important; }
    .stTabs [data-baseweb="tab-list"] { gap: 10px; height: 80px; }
    button[data-baseweb="tab"] {
        font-size: 32px !important; font-weight: 800 !important; height: 70px !important;
        padding: 0px 30px !important; background-color: #f0f2f6 !important;
        border-radius: 10px 10px 0px 0px !important; margin-right: 5px !important;
    }
    button[data-baseweb="tab"][aria-selected="true"] {
        color: white !important; background-color: #FF4B4B !important;
    }
    .sticky-header-row {
        position: -webkit-sticky;
        position: sticky;
        top: 0px;
        z-index: 1000;
        background-color: white !important;
        padding: 10px 0px;
        margin-bottom: 5px;
    }
    </style>
""", unsafe_allow_html=True)

if 'diary_entries' not in st.session_state:
    st.session_state.diary_entries = [{h: "" for h in INPUT_HEADERS} for _ in range(40)]

# ã‚¿ãƒ–æ§‹æˆã®æ›´æ–°
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ“ â‘  ãƒ‡ãƒ¼ã‚¿ç™»éŒ²", 
    "ğŸ“Š â‘¡ åº—èˆ—ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³", 
    "ğŸ“‚ â‘¢ æŠ•ç¨¿æ—¥è¨˜æ–‡ç®¡ç†", 
    "ğŸ“¸ â‘£ æŠ•ç¨¿ç”»åƒç®¡ç†",
    "ğŸ“š â‘¤ ä½¿ç”¨å¯èƒ½æ—¥è¨˜æ–‡",
    "ğŸ–¼ â‘¥ ä½¿ç”¨å¯èƒ½ç”»åƒ"
])

combined_data = []
acc_summary = {}; acc_counts = {}
try:
    all_ws = SPRS.worksheets()
    ws_dict = {ws.title: ws for ws in all_ws}
    for code, s_name in POSTING_ACCOUNT_SHEETS.items():
        if s_name in ws_dict:
            rows = ws_dict[s_name].get_all_values()
            if len(rows) > 1:
                for i, r in enumerate(rows[1:]):
                    if any(str(c).strip() for c in r[:7]):
                        combined_data.append([code, i+2] + [r[j] if j<len(r) else "" for j in range(7)])
                        a, s, m = str(r[0]).strip(), str(r[1]).strip(), str(r[2]).strip()
                        acc_counts[code] = acc_counts.get(code, 0) + 1
                        if code not in acc_summary: acc_summary[code] = {}
                        if a not in acc_summary[code]: acc_summary[code][a] = set()
                        acc_summary[code][a].add(f"{m} : {s}")
except: pass

# =========================================================
# --- Tab 1: ğŸ“ â‘  ãƒ‡ãƒ¼ã‚¿ç™»éŒ² (å®Œå…¨ãƒªãƒ­ãƒ¼ãƒ‰åœæ­¢ãƒ»å®‰å®šç‰ˆ) ---
# =========================================================
with tab1:
    st.header("1ï¸âƒ£ æ–°è¦ãƒ‡ãƒ¼ã‚¿ç™»éŒ²")
    
    # ğŸ’¡ st.form ã‚’ä½¿ã†ã“ã¨ã§ã€Œé€ä¿¡ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¾ã§ä¸€åˆ‡ãƒªãƒ­ãƒ¼ãƒ‰ã—ãªã„ã€çŠ¶æ…‹ã‚’ä½œã‚Šã¾ã™
    with st.form("diary_input_form", clear_on_submit=False):
        # åŸºæœ¬æƒ…å ±
        c1, c2, c3, c4 = st.columns(4)
        target_acc = c1.selectbox("ğŸ‘¤ æŠ•ç¨¿ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", POSTING_ACCOUNT_OPTIONS, key="sel_acc_f")
        target_media = c2.selectbox("ğŸŒ åª’ä½“", MEDIA_OPTIONS, key="sel_media_f")
        global_area = c3.text_input("ğŸ“ ã‚¨ãƒªã‚¢", key="in_area_f")
        global_store = c4.text_input("ğŸ¢ åº—å", key="in_store_f")
        
        st.subheader("ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±")
        c5, c6 = st.columns(2)
        login_id = c5.text_input("ID", key="login_id_f")
        login_pw = c6.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", key="login_pw_f")
        
        st.markdown("---")
        st.subheader("ğŸ“¸ æŠ•ç¨¿å†…å®¹å…¥åŠ›")

        # ãƒ˜ãƒƒãƒ€ãƒ¼å›ºå®šè¡¨ç¤ºï¼ˆHTMLï¼‰
        st.markdown("""
            <div style="display: flex; flex-direction: row; border-bottom: 2px solid #444; background-color: #f0f2f6; padding: 10px; border-radius: 5px 5px 0 0;">
                <div style="flex: 1; font-weight: bold; color: black;">æ™‚é–“</div>
                <div style="flex: 1; font-weight: bold; color: black;">åå‰</div>
                <div style="flex: 2; font-weight: bold; color: black;">ã‚¿ã‚¤ãƒˆãƒ«</div>
                <div style="flex: 3; font-weight: bold; color: black;">æœ¬æ–‡</div>
                <div style="flex: 2; font-weight: bold; color: black;">ç”»åƒ</div>
            </div>
        """, unsafe_allow_html=True)

        # ãƒ•ã‚©ãƒ¼ãƒ å†…ã®å…¥åŠ›ã‚’å—ã‘å–ã‚‹ãŸã‚ã®ãƒªã‚¹ãƒˆ
        form_entries = []
        for i in range(40):
            cols = st.columns([1, 1, 2, 3, 2])
            e_time = cols[0].text_input(f"t{i}", key=f"f_t_{i}", label_visibility="collapsed")
            e_name = cols[1].text_input(f"n{i}", key=f"f_n_{i}", label_visibility="collapsed")
            e_title = cols[2].text_area(f"ti{i}", key=f"f_ti_{i}", height=68, label_visibility="collapsed")
            e_body = cols[3].text_area(f"b{i}", key=f"f_b_{i}", height=68, label_visibility="collapsed")
            e_img = cols[4].file_uploader(f"g{i}", key=f"f_img_{i}", label_visibility="collapsed")
            
            form_entries.append({
                'æŠ•ç¨¿æ™‚é–“': e_time, 
                'å¥³ã®å­ã®åå‰': e_name, 
                'ã‚¿ã‚¤ãƒˆãƒ«': e_title, 
                'æœ¬æ–‡': e_body, 
                'img': e_img
            })

        # ğŸ’¡ Formå°‚ç”¨ã®é€ä¿¡ãƒœã‚¿ãƒ³ï¼ˆã“ã‚Œä»¥å¤–ã®æ“ä½œã§ã¯ãƒªãƒ­ãƒ¼ãƒ‰ãŒç™ºç”Ÿã—ã¾ã›ã‚“ï¼‰
        submit_button = st.form_submit_button("ğŸ”¥ ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬ç™»éŒ²ã™ã‚‹", type="primary", use_container_width=True)

    # é€ä¿¡ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå¾Œã®å‡¦ç†ï¼ˆã“ã“ã‹ã‚‰APIãŒå‹•ãï¼‰
    if submit_button:
        valid_data = [e for e in form_entries if e['æŠ•ç¨¿æ™‚é–“'] and e['å¥³ã®å­ã®åå‰']]
        if not valid_data or not global_area or not global_store:
            st.error("âš ï¸ å…¥åŠ›ä¸è¶³ï¼šã‚¨ãƒªã‚¢ã€åº—åã€ãŠã‚ˆã³å°‘ãªãã¨ã‚‚1ä»¶ä»¥ä¸Šã®ã€Œæ™‚é–“ãƒ»åå‰ã€ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            progress_text = st.empty()
            try:
                # 1. ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                progress_text.info("ğŸ“¸ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...")
                for e in valid_data:
                    if e['img']: 
                        # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–¢æ•°ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆe['img']ã‚’æ¸¡ã™ï¼‰
                        gcs_upload_wrapper(e['img'], e, global_area, global_store)
                
                # 2. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼ˆæ—¥è¨˜ï¼‰ç™»éŒ²
                progress_text.info("ğŸ“ æ—¥è¨˜æ–‡ã‚’ç™»éŒ²ä¸­...")
                ws_main = SPRS.worksheet(POSTING_ACCOUNT_SHEETS[target_acc])
                rows_main = [[global_area, global_store, target_media, e['æŠ•ç¨¿æ™‚é–“'], e['å¥³ã®å­ã®åå‰'], e['ã‚¿ã‚¤ãƒˆãƒ«'], e['æœ¬æ–‡']] for e in valid_data]
                ws_main.append_rows(rows_main, value_input_option='USER_ENTERED')
                
                # 3. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼ˆã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ï¼‰ç™»éŒ²
                progress_text.info("ğŸ” ãƒ­ã‚°ã‚¤ãƒ³æƒ…å ±ã‚’ç™»éŒ²ä¸­...")
                ws_status = STATUS_SPRS.worksheet(POSTING_ACCOUNT_SHEETS[target_acc])
                ws_status.append_row([global_area, global_store, target_media, login_id, login_pw], value_input_option='USER_ENTERED')
                
                progress_text.empty()
                st.success(f"âœ… {len(valid_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ­£å¸¸ã«ç™»éŒ²ã—ã¾ã—ãŸï¼")
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¶ˆå»ã—ã¦ä»–ã‚¿ãƒ–ã«ã‚‚åæ˜ 
                st.cache_data.clear()
                # ç™»éŒ²å®Œäº†å¾Œã«ç”»é¢ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãŸã‚ã«ãƒªãƒ­ãƒ¼ãƒ‰
                st.rerun()

            except Exception as e:
                st.error(f"âŒ ç™»éŒ²ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
# =========================================================
# --- Tab 2: ğŸ“Š å…¨ã‚¢ã‚«ã‚¦ãƒ³ãƒˆåº—èˆ—ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³ (ä¿®æ­£ç‰ˆ) ---
# =========================================================
with tab2:
    st.markdown("## ğŸ“Š åº—èˆ—ã‚¢ã‚«ã‚¦ãƒ³ãƒˆçŠ¶æ³")
    if combined_data:
        for acc_code in POSTING_ACCOUNT_OPTIONS:
            count = acc_counts.get(acc_code, 0)
            st.markdown(f"### ğŸ‘¤ æŠ•ç¨¿{acc_code}ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ `{count} ä»¶`")
            if acc_code in acc_summary:
                areas = acc_summary[acc_code]
                area_cols = st.columns(len(areas) if len(areas) > 0 else 1)
                for idx, (area_name, shops) in enumerate(areas.items()):
                    with area_cols[idx]:
                        st.info(f"ğŸ“ **{area_name}**")
                        for shop in sorted(shops):
                            st.checkbox(f"{shop}", key=f"move_{acc_code}_{area_name}_{shop}")
        
        selected_shops = [
            {"acc": k.split('_')[1], "area": k.split('_')[2], "shop": k.split('_')[3].split(" : ")[-1]}
            for k, v in st.session_state.items() if k.startswith("move_") and v
        ]

        if selected_shops:
            # ğŸ’¡ ã“ã“ã‹ã‚‰ä¸‹ã®è¡Œã‚’ã™ã¹ã¦å³ã«1æ®µã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã—ã¾ã—ãŸ
            if st.button("ğŸš€ é¸æŠã—ãŸåº—èˆ—ã‚’ã€è½ã¡åº—ã€‘ã¸ç§»å‹•ã™ã‚‹", type="primary", use_container_width=True):
                st.session_state.confirm_move = True

            if st.session_state.get("confirm_move"):
                st.error("â— æœ¬å½“ã«å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ")
                col_yes, col_no = st.columns(2)
                
                if col_no.button("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«", use_container_width=True):
                    st.session_state.confirm_move = False
                    st.rerun()

                if col_yes.button("â­• ã¯ã„ã€å®Ÿè¡Œã—ã¾ã™", type="primary", use_container_width=True):
                    import time
                    try:
                        sh_stock = GC.open_by_key("1e-iLey43A1t0bIBoijaXP55t5fjONdb0ODiTS53beqM")
                        ws_stock = sh_stock.sheet1
                        sh_link = GC.open_by_key(ACCOUNT_STATUS_SHEET_ID)
                        
                        for item in selected_shops:
                            # â‘  æ—¥è¨˜ç§»å‹•
                            ws_main = SPRS.worksheet(POSTING_ACCOUNT_SHEETS[item['acc']])
                            main_data = ws_main.get_all_values()
                            for row_idx in range(len(main_data), 0, -1):
                                row = main_data[row_idx-1]
                                if len(row) >= 2 and row[1] == item['shop']:
                                    # A,Båˆ—ã‚’é£›ã°ã—ã¦ã€Cåˆ—ã«ã‚¿ã‚¤ãƒˆãƒ«(F)ã€Dåˆ—ã«æœ¬æ–‡(G)ã‚’ç™»éŒ²
                                    ws_stock.append_row([None, None, row[5], row[6]], value_input_option='USER_ENTERED')
                                    time.sleep(1.5) # APIåˆ¶é™(429)å¯¾ç­–
                                    ws_main.delete_rows(row_idx)

                            # â‘¡ ãƒªãƒ³ã‚¯å‰Šé™¤
                            ws_link = sh_link.worksheet(POSTING_ACCOUNT_SHEETS[item['acc']])
                            link_data = ws_link.get_all_values()
                            for row_idx in range(len(link_data), 0, -1):
                                if len(link_data[row_idx-1]) >= 2 and link_data[row_idx-1][1] == item['shop']:
                                    ws_link.delete_rows(row_idx)
                                    break
                            
                            # â‘¢ GCSç”»åƒç§»å‹• (ãƒ‘ã‚¹æ§‹é€ ç¶­æŒ)
                            bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
                            found_blobs = []
                            for pfx in [f"{item['area']}/{item['shop']}/", f"{item['area']}/ãƒ‡ãƒªã˜ã‚ƒ {item['shop']}/"]:
                                blobs = list(bucket.list_blobs(prefix=pfx))
                                if blobs:
                                    found_blobs = blobs
                                    break
                            for b in found_blobs:
                                file_name = b.name.split('/')[-1]
                                new_name = f"ã€è½ã¡åº—ã€‘/{item['shop']}/{file_name}"
                                bucket.copy_blob(b, bucket, new_name)
                                b.delete()
                        
                        st.success("ğŸ‰ ç§»å‹•å®Œäº†ï¼")
                        st.session_state.confirm_move = False
                        st.cache_data.clear() 
                        if 'diary_df' in st.session_state: del st.session_state.diary_df
                        st.rerun()
                    except Exception as e:
                        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        
# =========================================================
# --- Tab 3: ğŸ“‚ â‘¢ æŠ•ç¨¿æ—¥è¨˜æ–‡ç®¡ç† (æ‰‹å‹•æ›´æ–°ãƒ»ã‚¨ãƒ©ãƒ¼é˜²æ­¢ç‰ˆ) ---
# =========================================================
with tab3:
    st.markdown("### ğŸ“‚ æŠ•ç¨¿æ—¥è¨˜æ–‡ç®¡ç† (ä¸€æ‹¬ç·¨é›†)")
    st.caption("â€»ã€Œä¸€æ‹¬ä¿å­˜ã€ã¾ãŸã¯ã€Œç·¨é›†ã‚’ãƒªã‚»ãƒƒãƒˆã€ã‚’æŠ¼ã™ã¾ã§ã€æœ€æ–°ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆçŠ¶æ…‹ã¯åæ˜ ã•ã‚Œã¾ã›ã‚“ã€‚")

    # ğŸ’¡ APIè² è·è»½æ¸›ï¼šã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒ‡ãƒ¼ã‚¿ãŒãªã„æ™‚ã ã‘èª­ã¿è¾¼ã‚€
    if combined_data:
        # 1. ç·¨é›†ç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã—ã¦ã®å½¹å‰²ï¼‰
        if 'edited_df_3' not in st.session_state:
            # èª­ã¿è¾¼ã¿æ™‚ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’ä½œæˆ
            st.session_state.df_orig_snapshot = pd.DataFrame(combined_data, columns=["ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "è¡Œç•ªå·"] + REGISTRATION_HEADERS)
            st.session_state.edited_df_3 = st.session_state.df_orig_snapshot.copy()

        # 2. æ¤œç´¢ãƒ»ãƒ•ã‚£ãƒ«ã‚¿æ©Ÿèƒ½ï¼ˆUIã®ã¿ã€‚APIã¯å©ã‹ãªã„ï¼‰
        c_search1, c_search2 = st.columns([1, 2])
        filter_acc = c_search1.multiselect("ğŸ‘¤ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã§çµã‚Šè¾¼ã¿", POSTING_ACCOUNT_OPTIONS, key="filter_acc_3")
        filter_text = c_search2.text_input("ğŸ” ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ (åº—åãƒ»åå‰ãªã©)", key="filter_text_3")

        # ç·¨é›†ç”¨ãƒ¯ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼
        working_df = st.session_state.edited_df_3.copy()
        df_orig = st.session_state.df_orig_snapshot

        # 3. å¤‰æ›´ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹ (ValueErrorã‚’å®Œå…¨ã«é˜²æ­¢)
        try:
            # å¸¸ã«åŒã˜ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ä½œæˆã•ã‚ŒãŸ snapshot ã¨æ¯”è¼ƒã™ã‚‹ãŸã‚å½¢çŠ¶ä¸ä¸€è‡´ãŒèµ·ããªã„
            diff_mask = (working_df != df_orig).any(axis=1)
        except ValueError:
            # ä¸‡ãŒä¸€ã®äº‹æ•…æ™‚ã®ã¿ãƒªã‚»ãƒƒãƒˆ
            if 'edited_df_3' in st.session_state: del st.session_state.edited_df_3
            st.rerun()

        working_df.insert(0, "çŠ¶æ…‹", diff_mask.map({True: "ğŸ”´ å¤‰æ›´ã‚ã‚Š", False: "ãƒ¼"}))

        # 4. ã‚½ãƒ¼ãƒˆãƒ»ãƒ•ã‚£ãƒ«ã‚¿
        working_df = working_df.sort_values(by=["çŠ¶æ…‹", "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"], ascending=[False, True])
        if filter_acc:
            working_df = working_df[working_df["ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"].isin(filter_acc)]
        if filter_text:
            working_df = working_df[working_df.astype(str).apply(lambda x: filter_text.lower() in x.str.lower().any(), axis=1)]

        # 5. ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°
        def highlight_changes(row):
            if row["çŠ¶æ…‹"] == "ğŸ”´ å¤‰æ›´ã‚ã‚Š":
                return ['background-color: #ffebee; color: #b71c1c; font-weight: bold'] * len(row)
            return [''] * len(row)

        styled_df = working_df.style.apply(highlight_changes, axis=1)

        # 6. ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿
        new_edited_df = st.data_editor(
            styled_df,
            key="main_editor_3",
            use_container_width=True,
            hide_index=True,
            disabled=["çŠ¶æ…‹", "ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ", "è¡Œç•ªå·"],
            height=600
        )

        # ç·¨é›†å†…å®¹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«å³æ™‚ä¿å­˜
        st.session_state.edited_df_3 = new_edited_df.drop(columns=["çŠ¶æ…‹"])

        # 7. ä¿å­˜ãƒ»ãƒªã‚»ãƒƒãƒˆå‡¦ç†
        c_save1, c_save2 = st.columns([4, 1])
        
        # --- ä¿å­˜ãƒœã‚¿ãƒ³ï¼šã“ã“ã§åˆã‚ã¦APIã‚’å©ã ---
        if c_save2.button("ğŸ”¥ ä¸€æ‹¬ä¿å­˜", type="primary", use_container_width=True):
            changed_rows = new_edited_df[new_edited_df["çŠ¶æ…‹"] == "ğŸ”´ å¤‰æ›´ã‚ã‚Š"]
            if changed_rows.empty:
                st.warning("å¤‰æ›´ç®‡æ‰€ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                with st.spinner("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°ä¸­..."):
                    import time
                    try:
                        for acc_code in POSTING_ACCOUNT_OPTIONS:
                            acc_changes = changed_rows[changed_rows["ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ"] == acc_code]
                            if acc_changes.empty: continue
                            
                            ws = SPRS.worksheet(POSTING_ACCOUNT_SHEETS[acc_code])
                            for _, row in acc_changes.iterrows():
                                row_idx = int(row["è¡Œç•ªå·"])
                                update_values = [str(row[h]) for h in REGISTRATION_HEADERS]
                                ws.update(f"A{row_idx}:G{row_idx}", [update_values], value_input_option='USER_ENTERED')
                                time.sleep(1.2) # APIåˆ¶é™å¯¾ç­–
                        
                        st.success("ğŸ‰ ä¿å­˜å®Œäº†ï¼æœ€æ–°æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
                        # ä¿å­˜æˆåŠŸå¾Œã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¶ˆã—ã¦æœ€æ–°åŒ–
                        if 'edited_df_3' in st.session_state: del st.session_state.edited_df_3
                        st.cache_data.clear()
                        st.rerun()
                    except Exception as e:
                        st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

        # --- ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ï¼šæœ€æ–°ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆçŠ¶æ…‹ã«æ›´æ–°ã™ã‚‹å½¹å‰² ---
        if c_save1.button("ğŸ”„ ç·¨é›†ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆæœ€æ–°çŠ¶æ…‹ã«æ›´æ–°ï¼‰"):
            if 'edited_df_3' in st.session_state: del st.session_state.edited_df_3
            st.cache_data.clear()
            st.rerun()

    else:
        st.info("ç·¨é›†å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
# =========================================================
# --- Tab 4: ğŸ“¸ â‘£ æŠ•ç¨¿ç”»åƒç®¡ç† (æ‰‹å‹•æ›´æ–°ãƒ»Fragmenté«˜é€Ÿç‰ˆ) ---
# =========================================================
with tab4:
    st.header("ğŸ“¸ æŠ•ç¨¿ç”»åƒç®¡ç†")
    
    # 1. éšå±¤æ§‹é€ å–å¾—ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ï¼ˆupdate_tickã§åˆ¶å¾¡ï¼‰
    @st.cache_data
    def get_gcs_hierarchy_v8(update_tick):
        try:
            # delimiter='/' ã‚’ä½¿ã£ã¦åŠ¹ç‡çš„ã«å–å¾—
            blobs = GCS_CLIENT.list_blobs(GCS_BUCKET_NAME, prefix="", delimiter='/')
            list(blobs) # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚¿ã‚’å›ã™
            areas = [p.replace("/", "") for p in blobs.prefixes if "ã€è½ã¡åº—ã€‘" not in p and p != "/"]
            
            hierarchy = {}
            for area in areas:
                area_blobs = GCS_CLIENT.list_blobs(GCS_BUCKET_NAME, prefix=f"{area}/", delimiter='/')
                list(area_blobs)
                hierarchy[area] = [p for p in area_blobs.prefixes]
            return hierarchy
        except: return {}

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆæ›´æ–°ç”¨ã‚­ãƒ¼ï¼‰
    if 'tab4_hierarchy_tick' not in st.session_state:
        st.session_state.tab4_hierarchy_tick = 0

    # æ›´æ–°ãƒœã‚¿ãƒ³
    col_ref, _ = st.columns([1.5, 4])
    if col_ref.button("ğŸ”„ ã‚¨ãƒªã‚¢ãƒ»åº—èˆ—ãƒªã‚¹ãƒˆã‚’æ›´æ–°", key="ref_hierarchy_4"):
        st.session_state.tab4_hierarchy_tick += 1
        st.cache_data.clear()
        st.rerun()

    hierarchy = get_gcs_hierarchy_v8(st.session_state.tab4_hierarchy_tick)

    if hierarchy:
        c_sel1, c_sel2 = st.columns(2)
        selected_area = c_sel1.selectbox("ğŸ“ ã‚¨ãƒªã‚¢", ["é¸æŠã—ã¦ãã ã•ã„"] + list(hierarchy.keys()), key="sel_area_4")
        
        if selected_area != "é¸æŠã—ã¦ãã ã•ã„":
            store_paths = hierarchy[selected_area]
            store_options = {p.split('/')[-2]: p for p in store_paths}
            selected_store_name = c_sel2.selectbox("ğŸ¢ åº—èˆ—", ["é¸æŠã—ã¦ãã ã•ã„"] + list(store_options.keys()), key="sel_store_4")

            if selected_store_name != "é¸æŠã—ã¦ãã ã•ã„":
                target_path = store_options[selected_store_name]
                active_bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)

                # --- å‰Šé™¤ãƒ»é¸æŠãƒ­ã‚¸ãƒƒã‚¯ã‚’ç‹¬ç«‹ã•ã›ã‚‹Fragment ---
                @st.fragment
                def image_grid_fragment(path, store_name):
                    # ç”»åƒãƒªã‚¹ãƒˆå–å¾—ï¼ˆã“ã“ã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’åˆ©ç”¨ï¼‰
                    blobs = list(active_bucket.list_blobs(prefix=path))
                    img_names = [bl.name for bl in blobs if bl.name != path and bl.name.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]

                    if not img_names:
                        st.info("ç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                        return

                    search_query = st.text_input("ğŸ” åå‰ã§æ¤œç´¢", key="search_4_v8")
                    display_names = [n for n in img_names if search_query.lower() in n.split('/')[-1].lower()]

                    # æ“ä½œãƒœã‚¿ãƒ³
                    btn_c1, btn_c2, btn_c3, btn_c4 = st.columns([1, 1, 2, 2])
                    
                    # è¤‡æ•°é¸æŠã®ç®¡ç†ã¯ session_state ã‚’åˆ©ç”¨
                    selected_items = [n for n in display_names if st.session_state.get(f"del_4_{n}")]

                    # ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å‡¦ç† (ZIP)
                    if selected_items:
                        if len(selected_items) == 1:
                            btn_c3.download_button("ğŸ’¾ 1æšä¿å­˜", active_bucket.blob(selected_items[0]).download_as_bytes(), file_name=selected_items[0].split('/')[-1], type="primary", use_container_width=True)
                        else:
                            zip_buf = BytesIO()
                            with zipfile.ZipFile(zip_buf, "w") as zf:
                                for p in selected_items:
                                    zf.writestr(f"{store_name}/{p.split('/')[-1]}", active_bucket.blob(p).download_as_bytes())
                            btn_c3.download_button(f"â¬‡ï¸ {len(selected_items)}æšZIPä¿å­˜", zip_buf.getvalue(), file_name=f"{store_name}.zip", type="primary", use_container_width=True)

                        if btn_c4.button(f"ğŸ—‘ {len(selected_items)}æšå‰Šé™¤", type="secondary", use_container_width=True):
                            st.session_state.confirm_del_4 = True

                    # å‰Šé™¤ç¢ºèª
                    if st.session_state.get("confirm_del_4"):
                        st.error("âš ï¸ æœ¬å½“ã«å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ")
                        if st.button("â­• å®Ÿè¡Œ"):
                            for n in selected_items: active_bucket.blob(n).delete()
                            st.session_state.confirm_del_4 = False
                            st.cache_data.clear()
                            st.rerun()

                    st.markdown(f"**è¡¨ç¤ºä¸­: {len(display_names)} æš**")
                    
                    # ç”»åƒã‚°ãƒªãƒƒãƒ‰ï¼ˆ8åˆ—ï¼‰
                    cols = st.columns(8)
                    for idx, b_name in enumerate(display_names):
                        with cols[idx % 8]:
                            # ğŸ’¡ æœ‰åŠ¹æœŸé™ã‚’æœ€å¤§(7æ—¥é–“)ã«è¨­å®šã—ãŸURLå–å¾—ï¼ˆåˆ¥é–¢æ•°ã§å®šç¾©æ¸ˆã¿ã¨æƒ³å®šï¼‰
                            # get_cached_urlã®ä¸­ã§ expiration=datetime.timedelta(days=7) ã«å¤‰æ›´ã—ã¦ãã ã•ã„
                            st.image(get_cached_url(b_name), use_container_width=True)
                            st.caption(b_name.split('/')[-1])
                            st.checkbox("é¸", key=f"del_4_{b_name}", label_visibility="collapsed")

                # Fragmentå®Ÿè¡Œ
                image_grid_fragment(target_path, selected_store_name)

                # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯Fragmentã®å¤–ã§ç®¡ç†ï¼ˆãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆãŒå¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
                with st.expander("â• ç”»åƒã‚’ã“ã®åº—èˆ—ã«è¿½åŠ "):
                    up_files = st.file_uploader("ç”»åƒã‚’ãƒ‰ãƒ­ãƒƒãƒ—", accept_multiple_files=True, type=["jpg","jpeg","png","webp"])
                    if st.button("ğŸš€ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹"):
                        if up_files:
                            for f in up_files:
                                active_bucket.blob(f"{target_path}{f.name}").upload_from_string(f.getvalue(), content_type=f.type)
                            st.cache_data.clear()
                            st.rerun()
# =========================================================
# --- Tab 5: ğŸ“š â‘¤ ä½¿ç”¨å¯èƒ½æ—¥è¨˜æ–‡ (æ‰‹å‹•æ›´æ–°ãƒ»APIè² è·æœ€å°ç‰ˆ) ---
# =========================================================
with tab5:
    st.header("5ï¸âƒ£ ä½¿ç”¨å¯èƒ½æ—¥è¨˜æ–‡")
    
    # ğŸ’¡ å¼•æ•°ã«ã€Œæ›´æ–°ç”¨ã‚­ãƒ¼ã€ã‚’æŒãŸã›ã‚‹ã“ã¨ã§ã€ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã®ã¿ä¸­èº«ã‚’å®Ÿè¡Œã•ã›ã‚‹
    @st.cache_data
    def get_usable_diary_data(update_tick):
        # ã“ã®ä¸­èº«ã¯ update_tick ãŒå¤‰ã‚ã‚‰ãªã„é™ã‚Šã€ä½•åº¦ãƒªãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚‚å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“
        tmp_sprs = GC.open_by_key("1e-iLey43A1t0bIBoijaXP55t5fjONdb0ODiTS53beqM")
        tmp_ws = tmp_sprs.sheet1 
        return tmp_ws.get_all_values()

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§æ›´æ–°ç”¨ã‚­ãƒ¼ã‚’ç®¡ç†
    if 'tab5_update_tick' not in st.session_state:
        st.session_state.tab5_update_tick = 0

    # --- æ›´æ–°ãƒœã‚¿ãƒ³ã®é…ç½® ---
    col_refresh, _ = st.columns([1, 4])
    if col_refresh.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚’æœ€æ–°ã«æ›´æ–°", key="refresh_tab5", use_container_width=True):
        st.session_state.tab5_update_tick += 1  # ã‚­ãƒ¼ã‚’å¢—ã‚„ã™ã“ã¨ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°ã•ã›ã‚‹
        st.cache_data.clear()
        st.rerun()

    try:
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        tmp_data = get_usable_diary_data(st.session_state.tab5_update_tick)
        
        if len(tmp_data) > 1:
            df_usable = pd.DataFrame(tmp_data[1:], columns=tmp_data[0])
            st.dataframe(df_usable, use_container_width=True, height=600, hide_index=True)
        else:
            st.info("è¡¨ç¤ºã§ãã‚‹æ—¥è¨˜æ–‡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

    except Exception as e:
        if "429" in str(e):
            st.error("ğŸš¨ APIåˆ¶é™ä¸­ã§ã™ã€‚1åˆ†å¾…ã£ã¦ã‹ã‚‰ã€Œæœ€æ–°ã«æ›´æ–°ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
        else:
            st.error(f"èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
# =========================================================
# --- Tab 6: ğŸ–¼ â‘¥ ä½¿ç”¨å¯èƒ½ç”»åƒï¼ˆè½ã¡åº—ï¼‰ 2æ®µæ§‹ãˆå‰Šé™¤ç‰ˆ ---
# =========================================================
with tab6:
    st.header("ğŸ–¼ ä½¿ç”¨å¯èƒ½ç”»åƒï¼ˆè½ã¡åº—ï¼‰")
    
    ROOT_PATH = "ã€è½ã¡åº—ã€‘/"

    # 1. ãƒ•ã‚©ãƒ«ãƒ€ãƒªã‚¹ãƒˆå–å¾—ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–
    @st.cache_data
    def get_ochimise_folders_v8(update_tick):
        try:
            blobs = GCS_CLIENT.list_blobs(GCS_BUCKET_NAME, prefix=ROOT_PATH, delimiter='/')
            list(blobs)
            return blobs.prefixes
        except: return []

    if 'tab6_hierarchy_tick' not in st.session_state:
        st.session_state.tab6_hierarchy_tick = 0

    col_ref, _ = st.columns([1.5, 4])
    if col_ref.button("ğŸ”„ ãƒ•ã‚©ãƒ«ãƒ€ãƒªã‚¹ãƒˆã‚’æ›´æ–°", key="ref_hierarchy_6"):
        st.session_state.tab6_hierarchy_tick += 1
        st.cache_data.clear()
        st.rerun()

    folders = get_ochimise_folders_v8(st.session_state.tab6_hierarchy_tick)
    show_all = st.checkbox("ğŸ“‚ å…¨ç”»åƒè¡¨ç¤ºï¼ˆå…¨ã¦ã®åº—èˆ—ã‚’ã¾ã¨ã‚ã¦è¡¨ç¤ºï¼‰", key="show_all_ochimise")

    @st.fragment
    def ochimise_grid_fragment(folders, show_all):
        bucket = GCS_CLIENT.bucket(GCS_BUCKET_NAME)
        target_images = []
        current_label = "è½ã¡åº—"

        # --- ç”»åƒãƒªã‚¹ãƒˆå–å¾— ---
        if show_all:
            @st.cache_data(ttl=600)
            def get_all_ochimise_images():
                blobs = list(bucket.list_blobs(prefix=ROOT_PATH))
                return [bl.name for bl in blobs if bl.name != ROOT_PATH and bl.name.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]
            target_images = get_all_ochimise_images()
            current_label = "å…¨åº—èˆ—ä¸€æ‹¬"
        elif folders:
            folder_opts = {f.replace(ROOT_PATH, "").replace("/", ""): f for f in folders}
            selected_key = st.selectbox("ğŸ“ åº—èˆ—ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠ", ["é¸æŠã—ã¦ãã ã•ã„"] + list(folder_opts.keys()), key="sel_ochimise_folder_f")
            if selected_key != "é¸æŠã—ã¦ãã ã•ã„":
                target_path = folder_opts[selected_key]
                blobs = list(bucket.list_blobs(prefix=target_path, delimiter='/'))
                target_images = [bl.name for bl in blobs if bl.name != target_path and bl.name.lower().endswith(('.jpg', '.jpeg', '.png', '.webp'))]
                current_label = selected_key

        if target_images:
            st.markdown("---")
            search_q = st.text_input("ğŸ” åå‰ã§æ¤œç´¢ (è½ã¡åº—å†…)", key="search_6_f")
            display_imgs = [n for n in target_images if search_q.lower() in n.split('/')[-1].lower()]

            # ãƒœã‚¿ãƒ³é…ç½®ç”¨ã®ã‚«ãƒ©ãƒ 
            c1, c2, c3, c4 = st.columns([1, 1, 2, 2])
            
            # å…¨é¸æŠãƒ»è§£é™¤
            if c1.button("âœ… å…¨é¸æŠ", key="all_6_f", use_container_width=True):
                for n in display_imgs: st.session_state[f"sel_6_{n}"] = True
                st.rerun()
            if c2.button("â¬œï¸ è§£é™¤", key="none_6_f", use_container_width=True):
                for n in display_imgs: st.session_state[f"sel_6_{n}"] = False
                st.rerun()

            selected_items = [n for n in display_imgs if st.session_state.get(f"sel_6_{n}")]

            # --- ğŸ”¥ ã“ã“ã‹ã‚‰ãŒ2æ®µæ§‹ãˆã®ãƒ­ã‚¸ãƒƒã‚¯ ---
            if selected_items:
                # 1. ã¾ãšZIPã‚’ä½œæˆ
                zip_buf = BytesIO()
                with zipfile.ZipFile(zip_buf, "w") as zf:
                    for p in selected_items:
                        zf.writestr(f"è½ã¡åº—_{current_label}/{p.split('/')[-1]}", bucket.blob(p).download_as_bytes())
                
                # ã€1æ®µç›®ã€‘ä¿å­˜ãƒœã‚¿ãƒ³
                c3.download_button(
                    label=f"â‘  {len(selected_items)}æšã‚’ä¿å­˜(ZIP)",
                    data=zip_buf.getvalue(),
                    file_name=f"è½ã¡åº—_{current_label}.zip",
                    type="primary",
                    use_container_width=True,
                    key="dl_btn_6"
                )

                # ã€2æ®µç›®ã€‘ç‰©ç†å‰Šé™¤ãƒœã‚¿ãƒ³ï¼ˆèµ¤è‰²ã§è­¦å‘Šï¼‰
                # ãƒ­ãƒƒã‚¯ã‚’ã‹ã‘ã‚‹ãŸã‚ã€ä»–ã®ç”»åƒé¸æŠä¸­ã¯ã€Œä¿å­˜ã€ã™ã‚‹ã¾ã§ç›®ç«‹ã¤ã‚ˆã†ã«è¡¨ç¤º
                if c4.button(f"â‘¡ ä¿å­˜å®Œäº†ãƒ»å‰Šé™¤å®Ÿè¡Œ", type="secondary", use_container_width=True, help="ä¿å­˜ã—ãŸå¾Œã«å¿…ãšæŠ¼ã—ã¦ãã ã•ã„ã€‚GCSã‹ã‚‰æ¶ˆå»ã—ã¾ã™ã€‚"):
                    with st.spinner("å‰Šé™¤ä¸­..."):
                        for n in selected_items:
                            bucket.blob(n).delete()
                        # å‰Šé™¤ãŒçµ‚ã‚ã£ãŸã‚‰é¸æŠçŠ¶æ…‹ã‚’ã‚¯ãƒªã‚¢
                        for n in selected_items:
                            st.session_state[f"sel_6_{n}"] = False
                        st.success(f"âœ… {len(selected_items)}æšã‚’å®Œå…¨ã«æ¶ˆå»ã—ã¾ã—ãŸã€‚")
                        st.cache_data.clear()
                        st.rerun()
                
                st.warning("âš ï¸ **ä½¿ã„å›ã—é˜²æ­¢ã®ãŸã‚ã€ä¿å­˜ãŒçµ‚ã‚ã£ãŸã‚‰å¿…ãšã€Œâ‘¡ å‰Šé™¤ã€ã‚’æŠ¼ã—ã¦çµ‚äº†ã—ã¦ãã ã•ã„ã€‚**")
            # ---------------------------------------

            st.write(f"**è¡¨ç¤ºæ•°: {len(display_imgs)}æš**")

            # ç”»åƒã‚°ãƒªãƒƒãƒ‰ï¼ˆé¸æŠä¸­ã¯ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’ã„ã˜ã‚‰ã›ãªã„ç­‰ã®å·¥å¤«ã‚‚å¯èƒ½ã§ã™ãŒã€ã¾ãšã¯ã‚·ãƒ³ãƒ—ãƒ«ã«ï¼‰
            cols = st.columns(8)
            for idx, b_name in enumerate(display_imgs):
                with cols[idx % 8]:
                    st.image(get_cached_url(b_name), use_container_width=True)
                    st.caption(b_name.split('/')[-1])
                    st.checkbox("é¸", key=f"sel_6_{b_name}", label_visibility="collapsed")
        else:
            if not show_all: st.info("è¡¨ç¤ºã™ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

    ochimise_grid_fragment(folders, show_all)

